{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "%\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\kernel}{\\mathbf{k}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import cnn_helper\n",
    "%aimport cnn_helper\n",
    "cnnh = cnn_helper.CNN_Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks (CNN): HIgh Level\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>TL;DR</b> \n",
    "    <br>\n",
    "    <ul>\n",
    "        <li> A single unit in Fully Connected (FC) Layer identifies the presence/absence of a single feature spanning the <b>entire</b> input</li>\n",
    "        <li>A single \"kernel\" in a Convolutional Layer identifies the presence/absence of a single feature</li>\n",
    "        <ul>\n",
    "            <li>Whose size is a fraction of the entire input</li>\n",
    "            <li>At <b>each</b> sub-span of the input</li>\n",
    "        </ul>\n",
    "        \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example**\n",
    "- FC: is the input image the digit \"8\"\n",
    "- CNN: are there one or more small \"8\"'s in the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have seen how the Fully Connected (FC) layer performs a template-matching on the layer's inputs.\n",
    "$$\n",
    "\\y_\\llp = a_\\llp ( \\W_\\llp \\y_{(\\ll-1)} + b )\n",
    "$$\n",
    "\n",
    "- Each element of $\\y_{(\\ll-1)}$ is independent\n",
    "    - there is no relationship between $\\y_{(\\ll-1), j}$ and $\\y_{(\\ll-1), j+1}$\n",
    "    - even though they are adjacent in the vector ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To see the lack of relationship:\n",
    "\n",
    "Let $\\text{perm}$ be a random ordering of the integers in the range $[1 \\ldots n]$.\n",
    "\n",
    "Then\n",
    "- $\\x[ \\text{perm} ]$ is a permutation of input $\\x$\n",
    "- $\\Theta[ \\text{perm} ]$ is the corresponding permutation of parametrs $\\Theta$.\n",
    "\n",
    "$$\n",
    "\\Theta^T \\cdot \\x = \\x[ \\text{perm} ] \\cdot \\Theta[ \\text{perm} ]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So a FC layer cannot take advantage of any explicit ordering among the input elements\n",
    "- timeseries of prices\n",
    "- adjacent pixels in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another issue with an FC layer:\n",
    "- The \"template\" $\\W_\\llp$ matches the full length of the input $\\y_{(\\ll-1)}$ \n",
    "\n",
    "There are cases where we might want to discover a feature\n",
    "- whose length is less than $n$\n",
    "- that occurs *anywhere* in the input, rather than at a fixed location\n",
    "\n",
    "For example\n",
    "- a spike in a timeseries\n",
    "- the presence of an \"eye\" in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Both these questions motivate the notion of convolutional matching\n",
    "- small templates\n",
    "- that are slid over the entire input\n",
    "\n",
    "By sliding the pattern over the entire input\n",
    "- we can detect the existence of the feature somewhere in the input\n",
    "- we can localize its location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>CNN convolution</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/CNN_convolution_1.jpg\" width=900></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We place $(3 \\times 3)$ Kernel (weight matrix) on the inputs ($\\y_{(0)}$, output of layer 0)\n",
    "- Performs dot product\n",
    "- Produces Layer 1 output ($\\y_{(1)}$) feature labelled $1$\n",
    "\n",
    "Slide the Kernel up and repeat:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>CNN convolution</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/CNN_convolution_2.jpg\" width=900></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The dot product *using the identical kernel weights* produces output ($\\y_{(1)}$) feature labelled $2$\n",
    "\n",
    "Repeat, centering the Kernel over each feature in $\\y_{(0)}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>CNN convolution</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/CNN_convolution_3.jpg\" width=900></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The output of a convolution is of similar size as the input\n",
    "- detects a specific feature *at each input location*\n",
    "\n",
    "So, for example, if there are\n",
    "- three spikes: will detect the \"is a spike\" feature in 3 locations\n",
    "- two eyes: will detect the \"is an eye\" feature in two locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The convolution operation is like\n",
    "- creating a small (size of template) FC layer\n",
    "- that is applied to each location\n",
    "\n",
    "So it \"fully connects\" *neighboring inputs* rather than the *entire input* and thus takes advantage\n",
    "of ordering present in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The template is called a *kernel* or *filter*\n",
    "- The output of a convolution is called a *feature map*\n",
    "\n",
    "Pre-Deep Learning: manually specified filters have a rich history for image recognition.\n",
    "\n",
    "Let's see some in action to get a better intuition.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "<center>Fully Connected vs Convolution</center>\n",
    "<tr>\n",
    "<img src=\"images/CNN_vs_FC.jpg\" width=600\">\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Fully Connected Layer\n",
    "    - each of the $n_{(l-1)}$ units of layer $(l-1)$ connected to each of the $n_\\llp$ units of layer $\\llp$\n",
    "    - $n_{(l-1)} * n_\\llp$ weights total\n",
    "- Convolutional Layer with 1D convolution, filter size 3\n",
    "    - groups of $3$ units of layer $(l-1)$ connected to *individual* units of layer $\\llp$\n",
    "    - using the *same* 3 weights\n",
    "    - 3 weights total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So a Convolutional Layer can use *many fewer* weights/parameters than a Fully Connected Layer.\n",
    "\n",
    "As we will see, this enables us to create *many* separate convolutions in a single layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNN advantages/disadvantages\n",
    "\n",
    "**Advantages**\n",
    "- Translational invariance\n",
    "    - feature can be anywhere\n",
    "- Locality\n",
    "    - feature depends on nearby features, not the entire set of features\n",
    "    - reduced number of parameters compared to a Fully Connected layer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Disadvantages**\n",
    "- Output feature map is roughly same size as input\n",
    "    - lots of computation to compute a single output feature\n",
    "        - one per feature of input map\n",
    "    - higher computation cost\n",
    "        - training and inference\n",
    "- Translational invariance not always a positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiple kernels\n",
    "\n",
    "We have thus far seen a *single* kernel, applied to a $N=2$ dimensional input $\\y_{(\\ll-1)}$.\n",
    "\n",
    "The output $\\y_\\llp$ is an $N$ dimensional feature map that identifies the presence/absence\n",
    "of a feature at each element of $\\y_{(\\ll-1)}$.\n",
    "\n",
    "Why not use *multiple* kernels to identify *multiple* features ?\n",
    "- Let Convolutional Layer $\\ll$ have $n_{\\llp,1}$ kernels\n",
    "- The output is $n_{\\llp,1}$ feature maps, one per kernel, identifying the presence/absence of one feature each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is similar in concept to a Fully Connected layer\n",
    "- Let FC layer $\\ll$ have $n_\\llp$ units/neurons\n",
    "- The output is a vector of $n_\\llp$ features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $(n_{(\\ll-1),1} \\times n_{(\\ll-1),2})$ denote the shape of $\\y_{(\\ll-1)}$.\n",
    "\n",
    "If Convolutional Layer $\\ll$ has $n_{\\llp,1}$ kernels\n",
    "- the output shape is $(n_{\\llp,1} \\times n_{(\\ll-1),1} \\times n_{(\\ll-1),2})$\n",
    "\n",
    "That is, the input is replicated $n_\\llp$ times, one per kernel of layer $\\ll$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "       <center>CNN convolution</center>\n",
    "    <tr>\n",
    "        <td><img src=\"images/CNN_feature_map.jpg\" width=600></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It also means that the matrix $\\kernel_\\llp$ representing the kernels at layer $\\ll$\n",
    "has the same number of dimensions as the output\n",
    "- the first dimension is the number of kernels\n",
    "- the rest of the dimensions are the size of each kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Higher dimensional input ($N > 2$)\n",
    "\n",
    "After applying $n_{\\llp,1}$ kernels to $N=2$ dimensional input $\\y_{(\\ll-1)}$\n",
    "of shape\n",
    "$(n_{(\\ll-1),1} \\times n_{(\\ll-1),2})$ \n",
    "we get a three dimensional output of shape $(n_{\\llp,1} \\times n_{(\\ll-1),1} \\times n_{(\\ll-1),2})$.\n",
    "\n",
    "What happens when input $\\y_{(\\ll-1)}$ is $N=3$ dimensional \n",
    "of shape\n",
    "$(n_{(\\ll-1),1} \\times n_{(\\ll-1),2} \\times _{(\\ll-1),3})$ ?\n",
    "\n",
    "- this can easily occur in layer $(\\ll-1)$ is a Convolutional Layer with $n_{(\\ll-1),1}$ kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If $\\y_{(\\ll-1)}$ is the output of a Convolutional Layer\n",
    "- $\\y_{(\\ll-1)}$ has $n_{(\\ll-1),1}$ features over a space of shape $(n_{(\\ll-1),2} \\times _{(\\ll-1),3})$\n",
    "\n",
    "Convolutional Layer $\\ll$ \n",
    "- combines  all $n_{(\\ll-1),1}$ input features at a single \"location\" \n",
    "- into a new synthetic *scalar* feature at the same location in output $\\y_\\llp$\n",
    "\n",
    "This means the output $\\y_\\llp$ is of shape $(n_{\\llp,1} \\times n_{(\\ll-1),2} \\times _{(\\ll-1),3})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This implies that *each kernel* of layer $\\ll$ is of dimension $N_{(\\ll-1)}$\n",
    "\n",
    "For example: if layer $(\\ll -1)$ has $N_{(\\ll -1)} = 3$ dimensions\n",
    "- each kernel of layer $\\ll$ is has 3 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kernel shape\n",
    "\n",
    "We see that a Convolutional Layer $\\ll$ transforms\n",
    "- an input of dimension $(n_{(\\ll-1),1} \\times n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "- into output with dimension $(n_{\\llp,1} \\times n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "\n",
    "If each kernel of layer $\\ll$ has shape $(k_1 \\times k_2)$ then the kernel matrix $\\kernel_\\llp$ for layer $\\ll$\n",
    "- has shape $(n_{\\llp,1} \\times k_1 \\times k_2)$\n",
    "- one kernel per output synthetic feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Receptive field\n",
    "\n",
    "The *receptive field* of a elements of a feature map\n",
    "- are the Layer 0 (input) features that affect features in the map.\n",
    "\n",
    "\n",
    "For ease of notation:\n",
    "- we assume $N=2$ as the dimension of the kernel\n",
    "- we assume that all $N$ dimensions of the kernel are the same ($f_\\llp$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So we will assume without loss of generality that\n",
    "- the \"height\" and \"width\" of a single kernel kernel is $(f \\times f)$\n",
    "- the full dimensionality of a single layer $\\ll$ kernel is $(n_{(\\ll-1),1} \\times f \\times f)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus the receptive field of a Convolutional Layer at layer $1$ is $(f \\times f)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Increasing the Receptive Field\n",
    "\n",
    "There are several ways to \"widen\" the receptive field\n",
    "- Increasing $f_\\llp$, the size of the kernel\n",
    "- Stacking Convolutional Layers\n",
    "- Stride\n",
    "- Pooling\n",
    "\n",
    "Striding and Pooling also have the effect of reducing the size of the output feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Size of output\n",
    "\n",
    "We can relate the size of a layer's output feature map to the size of its input feature map:\n",
    "\n",
    "- input $W_i \\times H_i \\times D_i$\n",
    "- $N$: input size $N \\times N$\n",
    "- $F$: filter size $F \\times F$\n",
    "- $S$: stride\n",
    "- $P$: padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No padding\n",
    "- output size $( (W_i -F)/S +1 ) \\times ( (H_i - F)/S +1 ) \\times D_o$\n",
    "\n",
    "Padding\n",
    "- output size $( (W_i -F +2P)/S +1 ) \\times ( (H_i - F +2P)/S +1 ) \\times D_o$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "    \n",
    "Assuming full padding, a layer $\\ll$ Convolutional Layer with $n_{\\llp,1}$ kernels will have output $\\y_\\llp$ dimension\n",
    "- $(n_{\\llp,1} \\times n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "    - $n_{\\llp,1}$ features\n",
    "    - over a spatial map of $(n_{(\\ll-1),2} \\times n_{(\\ll-1),3})$\n",
    "    \n",
    "That is, the number of features changes but the spatial dimension is similar to $\\y_{(\\ll-1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Down-sampling: Why does output size matter\n",
    "\n",
    "Convolution applies a kernel to *each* region of the input feature map (assuming $S=1$).\n",
    "\n",
    "Reducing the size of feature map at layer $(\\ll-1)$ \n",
    "- will reduce the number of operations\n",
    "performed by Convolution at layer $\\ll$.\n",
    "\n",
    "For image inputs (with thousands or millions of input features) there is a incentive to down-sample\n",
    "- Speed up training\n",
    "- Speed up inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Down-sample by\n",
    "- Increasing Stride\n",
    "- Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Number of parameters\n",
    "\n",
    "The real power of convolution comes from using the *same* filter against all locations of the input.\n",
    "\n",
    "As a result, the number of parameters is quite small (compared to a separate set of parameters per each input).\n",
    "\n",
    "- Dimension of a single filter $F \\times F \\times D_i$\n",
    "- $D_o$: number of output filters\n",
    "- total parameters: $F * F * D_i * D_o$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember: there is a depth to the input and the filter applies to the entire input depth\n",
    "- size of a filter $F *F * D_i$\n",
    "- number of filters: $D_o$, one per output channel\n",
    "- total: $F * F * D_i * D_o$\n",
    "\n",
    "If we were to have a separate filter for each input location, the number of parameters would increase\n",
    "by a factor of $W_i * H_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
