{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_examples_LSTM_text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PLjiZkWIwGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False\n",
        "\n",
        "if IN_COLAB:\n",
        "  print(\"We're running Colab\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uygaR2nLI0mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Running TensorFlow version \",tf.__version__)\n",
        "\n",
        "# Parse tensorflow version\n",
        "import re\n",
        "\n",
        "version_match = re.match(\"([0-9]+)\\.([0-9]+)\", tf.__version__)\n",
        "tf_major, tf_minor = int(version_match.group(1)) , int(version_match.group(2))\n",
        "print(\"Version {v:d}, minor {m:d}\".format(v=tf_major, m=tf_minor) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcRfl7sNhboO",
        "colab_type": "text"
      },
      "source": [
        "# Derived from https://keras.io/examples/lstm_text_generation/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-IH2DOpf5XZ",
        "colab_type": "code",
        "outputId": "979d26c9-5dce-4ab7-d6d7-4dd5e1550a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DRIVE_DIR=\"/content/gdrive/My Drive/\"\n",
        "\n",
        "import os \n",
        "MODEL_DIR=os.path.join(DRIVE_DIR, \"Colab Notebooks\", \"NYU\", \"Models\")\n",
        "modelDirExists = True if os.path.isdir(MODEL_DIR) else False\n",
        "\n",
        "if modelDirExists:\n",
        "  print(\"Saving checkpoints to \", MODEL_DIR)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Saving checkpoints to  /content/gdrive/My Drive/Colab Notebooks/NYU/Models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6pLOKSng1zy",
        "colab_type": "text"
      },
      "source": [
        "# Standard imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vb7M8JELpAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from __future__ import print_function\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import IPython\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOI2b8gvg9yN",
        "colab_type": "text"
      },
      "source": [
        "# Get the text file\n",
        "- create maps to map between characters and their integer encodings\n",
        "  - from character to integer\n",
        "  - from integer to character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNRoCXtug8oX",
        "colab_type": "code",
        "outputId": "525bea5f-aa7a-467f-b474-5c8ce23a7e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "path = get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 1us/step\n",
            "corpus length: 600893\n",
            "total chars: 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXrmtsAthNMx",
        "colab_type": "text"
      },
      "source": [
        "# Prepare the training data: creating example sequences/targets\n",
        "- example i: maxlen consecuitve characters\n",
        "  - text[i:i+ maxlen] training example: $x^{(i)}$\n",
        "  - text[maxlen] target: $y^{(i)}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZdPuW6EgCRS",
        "colab_type": "code",
        "outputId": "0efad62b-fdb1-4be2-df8d-0b6c2abb9436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 200285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMnLQsslpA76",
        "colab_type": "text"
      },
      "source": [
        "# Examine the prepared input: \n",
        "- x: a prefix (of length maxlen)\n",
        "- y: the following character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y77yYH68oV1S",
        "colab_type": "code",
        "outputId": "11ed5514-ab0e-4be9-fed9-b52f6cc80c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "for i, example in enumerate( zip(sentences, next_chars)):\n",
        "  if i > 10: break\n",
        "  else: pass\n",
        "  (sentence, next_char) = example\n",
        "  print(\"x: \", sentence, \", y: \", next_char)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x:  preface\n",
            "\n",
            "\n",
            "supposing that truth is a woma , y:  n\n",
            "x:  face\n",
            "\n",
            "\n",
            "supposing that truth is a woman-- , y:  w\n",
            "x:  e\n",
            "\n",
            "\n",
            "supposing that truth is a woman--wha , y:  t\n",
            "x:  \n",
            "supposing that truth is a woman--what t , y:  h\n",
            "x:  pposing that truth is a woman--what then , y:  ?\n",
            "x:  sing that truth is a woman--what then? i , y:  s\n",
            "x:  g that truth is a woman--what then? is t , y:  h\n",
            "x:  hat truth is a woman--what then? is ther , y:  e\n",
            "x:   truth is a woman--what then? is there n , y:  o\n",
            "x:  uth is a woman--what then? is there not  , y:  g\n",
            "x:   is a woman--what then? is there not gro , y:  u\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O5sy7RWiJGj",
        "colab_type": "text"
      },
      "source": [
        "# One Hot Encode the characters \n",
        "- in $x^{(i)},  y^{(i)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzkczyaeh8k5",
        "colab_type": "code",
        "outputId": "a06e02ec-c790-47a3-d80c-2b4634c52f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co02Jvz6lQe0",
        "colab_type": "text"
      },
      "source": [
        "# Examine the input shape\n",
        "- $x^{(i)}_{(t),j}$ is found at  $x[ i, t, j ]$\n",
        "\n",
        "  - example i\n",
        "  - time step/sequence element t\n",
        "  - a sequence element is a vector, index at position j\n",
        "    - length of OHE (number of distinct characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yxV52HOlS_e",
        "colab_type": "code",
        "outputId": "c536d840-df8c-4314-aeff-4187edf4dcf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"X shape: \", x.shape)\n",
        "print(\"\\tNumber of examples: \", x.shape[0])\n",
        "print(\"\\tEach example is sequence of length \", x.shape[1])\n",
        "print(\"\\tEach element of the sequence is of length \", x.shape[2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape:  (200285, 40, 57)\n",
            "\tNumber of examples:  200285\n",
            "\tEach example is sequence of length  40\n",
            "\tEach element of the sequence is of length  57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao6DVrY1iV5v",
        "colab_type": "text"
      },
      "source": [
        "# Utility routines\n",
        "\n",
        "The sample routine\n",
        "- takes the probability vector (one probability per potential next character)\n",
        "- uses it to randomly sample the next character to produce\n",
        "- `temperature`\n",
        "  - our model produces a probability from a score, using the softmax, as usual for Classifiers that we have studied\n",
        "  - softmax exagerates small differences in the score into larger differences in probability\n",
        "  - the `temperature` controls the degree of exageration\n",
        "- the routine recalculates the probability, using the desired temperature before sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0OzYFF8iYWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createModel():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "  model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "def plotModel(model, modelName):\n",
        "  plotFile = modelName + \".png\"\n",
        "  plot_model(model, plotFile, show_shapes=True)\n",
        "\n",
        "  return plotFile\n",
        "  \n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    diversities = [0.2, 0.5, 1.0, 1.2]\n",
        "    for diversity in diversities[:2]:\n",
        "        # print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('\\n----- Generating with seed (diversity={d:3.2f}): \"{sent:s}\"\\n\\t'.format(d=diversity, sent=sentence) )\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdA-rpuZgFJf",
        "colab_type": "code",
        "outputId": "ad299a3b-e491-4e93-8e06-a5fb38b76d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = createModel()\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy') #, optimizer=optimizer)\n",
        "\n",
        "plotFile = plotModel(model, \"first_model\")\n",
        "IPython.display.Image(plotFile) \n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEnCAYAAABosn4/AAAABmJLR0QA/wD/AP+gvaeTAAAgAElE\nQVR4nOzdeVxTV9oH8F+QJQRZFRBRlKUuIC6tzoiCVJmiwggioKjMlC4WpS1YHUsBHRUFoVrkRUVH\ni3TetgoqvuCG9lOVIq1aOha1OLWAWlHKVmQPsuS8fzjJGBKQhIRAeL6fT/7w3HPvee4F8njvPQuH\nMcZACCGEyEFD1QEQQggZuCiJEEIIkRslEUIIIXKjJEIIIURump0Lrl69ioSEBFXEQgghpB9zcnLC\nunXrxMok7kRKS0tx4sSJPguKkIHi2rVruHbtmqrDGFAePXpE3ydq4tq1a7h69apEucSdiNDx48eV\nGhAhA42/vz8A+tuQxbFjx7Bs2TK6ZmpA+PvfGb0TIYQQIjdKIoQQQuRGSYQQQojcKIkQQgiRGyUR\nQgghcqMkQkgfO3fuHAwNDXH69GlVh9IvrV69GhwOR/QJDAyUqPP1118jIiICAoEAPj4+sLKyApfL\nhaWlJby9vXHr1q1ex9HS0oIJEyZg48aNEtvy8vIwe/Zs8Hg8WFhYIDw8HE+fPpWrne3bt4udr/Az\nadIksXqvvvqq1HocDgdDhw4FAJw6dQrx8fHo6OgQ2zczM1Os/vDhw+WKVRpKIoT0MZo4+8VMTEyQ\nnZ2Nu3fvIiUlRWzb5s2bkZSUhMjISAgEAly5cgVHjhxBTU0N8vLywOfzMWfOHJSVlfUqhqioKNy9\ne1eivLCwEO7u7nBzc0NVVRVOnjyJw4cPY82aNb1qrzecnZ0BAF5eXuByuXBzc0Ntba1ou7e3Nx49\neoTc3Fx4eHgotG1KIoT0MU9PT9TV1WHRokWqDgV8Ph+zZs1SdRgSdHV1sWDBAowbNw46Ojqi8ri4\nOKSlpeHYsWPQ19cH8GwUtbOzM3g8HqytrRETE4O6ujp89tlncrf/3Xff4aeffpK6bdu2bRgxYgS2\nbt0KPT09ODk5ITw8HJ999hl+/vlnudr7/PPPwRgT+3Run8vlor6+XqJecHAwPvzwQ1G9sLAwTJky\nBR4eHmhvbwcAcDgcWFpawsXFBS+99JJcMXaFkgghg1hKSgoqKytVHUaPFBcXY9OmTdi6dSu4XC4A\nQFNTU+KxoI2NDQCgpKRErnb4fD42bNiAxMREiW3t7e04e/YsXF1dweFwROULFy4EYwxZWVlytdkT\n58+fFyVOodLSUvz000+YN2+eWPmWLVtQUFAg9RwUjZIIIX0oLy8PVlZW4HA42Lt3LwAgOTkZenp6\n4PF4yMrKwsKFC2FgYIBRo0bh6NGjon2TkpLA5XJhZmaG1atXw8LCAlwuF7NmzcL169dF9UJDQ6Gt\nrY0RI0aIyt59913o6emBw+GguroaALB27VqsX78eJSUl4HA4sLOzA/Dsy8rAwAAxMTF9cUl6LCkp\nCYwxeHl5dVuPz+cDAAwMDORqJyoqCu+++y5MTU0ltt27dw+NjY2wsrISK7e1tQUAhbyLkUVcXBzC\nwsIkyo2NjeHq6orExESlPz6lJEJIH3J2dsZ3330nVhYSEoIPPvgAfD4f+vr6SE9PR0lJCWxsbLBq\n1Sq0tbUBeJYcgoKC0NzcjLCwMDx48AA3btxAe3s7XnvtNZSWlgJ49mW7dOlSsTb27duHrVu3ipUl\nJiZi0aJFsLW1BWMMxcXFACB6KSsQCJRyDeR19uxZjB8/Hjwer9t633//PYD/vieQxbfffouSkhKs\nWLFC6vby8nIAkLgj4HK50NXVRUVFhcxtAkBERASMjY2hra0Na2trLF68GPn5+d3u8/jxY+Tk5MDX\n11fq9mnTpuHx48e4efOmXDH1FCURQvqRWbNmwcDAAKampggICEBTUxMePnwoVkdTUxMTJ06Ejo4O\n7O3tkZycjIaGBqSmpiokBk9PT9TX12PTpk0KOZ4iNDU14f79+6L/8UtTUVGBtLQ0hIWFwcnJ6YV3\nLJ3x+XysXbsWycnJXdYR9sAaMmSIxDYtLS3RXZAsXn/9dZw6dQqlpaVobGzE0aNH8fDhQ7i6uqKw\nsLDL/eLi4vD+++9DQ0P617jw3cft27dljkkWlEQI6ae0tbUBQHQn0pXp06eDx+PJ/VJ3IKisrARj\nrNu7ECcnJ4SFhWHx4sXIzs6GlpaWTG1ERkbinXfegaWlZZd1hO9ihC+sn9fa2gpdXV2Z2gSA0aNH\nY9q0aRg6dCi0tbUxc+ZMpKamgs/nY9++fVL3KSsrw6lTpxAUFNTlcYXXSt67o57qchZfQsjAoaOj\ng6qqKlWHoTQtLS0AINZTqzMzMzOkpKTAwcFB5uPn5eXh9u3bL1xLSfieqb6+Xqy8ubkZLS0tsLCw\nkLltaRwdHTFkyBD88ssvUrfHx8dj1apVoqQmjTChCa+dstCdCCEDXFtbG2prazFq1ChVh6I0wi/E\nzoPonmdqagojIyO5jp+SkoKLFy9CQ0NDNCBP+GI9JiYGHA4HP/zwA6ytraGvr49ff/1VbH/h+6TJ\nkyfL1X5nAoEAAoFAatIsLy/HkSNHEBIS0u0xWltbAUCuuyNZUBIhZIDLyckBYwwzZ84UlWlqar7w\nMdhAYmZmBg6Hg7q6ui7rnD59uttHUd1JTU2VGH8hvLOLiooCYwzTp0+HpqYmPDw8kJubK9bxIDs7\nGxwOR+b3MAAwf/58ibL8/HwwxuDk5CSxLT4+HoGBgTAxMen2uMJrZW5uLnNMsqAkQsgAIxAI8OTJ\nE7S3t+PWrVtYu3YtrKysxJ6P29nZoaamBpmZmWhra0NVVZXE/56BZyPDy8rK8ODBAzQ0NKCtrQ3Z\n2dn9rosvj8eDjY0NHj16JHV7cXExzM3NsWzZMoltAQEBMDc3x40bNxQSy6ZNm1BRUYHNmzejqakJ\nV69exc6dOxEUFITx48fL3O7jx4+RlpaG2tpatLW14erVq3j77bdhZWUlMQq+oqIChw8fxgcffPDC\nOIXXytHRUY6z7DlKIoT0ob1792LGjBkAgPDwcHh7eyM5ORm7d+8G8OxxyL1793Do0CGsX78eALBg\nwQIUFRWJjtHS0gJHR0fo6urCxcUF48aNw+XLl8UefYSEhGDu3LlYvnw5xo8fj23btokeazg5OYm6\nA69ZswZmZmawt7eHh4cHampq+uQ6yMPT0xOFhYVSe0B1NxaitbUVlZWVChsI6ODggAsXLuCrr77C\nsGHD4OvrizfffBP79++Xq90FCxZg48aNGDVqFHg8HpYuXYrZs2fj2rVrGDZsmFjdjz/+GF5eXhLj\nVKTJz8+HpaWlwh6xdYl1kp6ezqQUEzLo+fn5MT8/P5XGEBwczExMTFQagyzk+T4JDg5mlpaWEuVF\nRUVMU1OTff755zIdr6Ojg7m4uLCUlBSZ9ustVbXLGGPV1dWMy+WyXbt2SWwLCwtjw4YNk/mYXf3+\n050IIQNMdy+X1QWfz8eFCxdQVFQkekFsZ2eH6OhoREdHo7GxsUfH6ejoQGZmJhoaGhAQEKDMkPtF\nu0JbtmzB1KlTERoaCuDZnVpZWRny8vJEnQAUhZIIIaTfqampEU3A+Oabb4rKIyIi4O/vj4CAgG5f\nsgvl5OQgIyMD2dnZLxzprkiqahcAEhISUFBQgHPnzonGymRlZYkmYDx79qxC2+t1Etm1a5eo58SB\nAwcUEZPSqMM6DteuXcPEiRNFXRHNzc2xfft2VYclJiMjAzY2NqKukiNGjJC6JgSRTWRkJFJTU1FX\nVwdra2ucOHFC1SEpxYEDB8R6SX3xxRdi22NiYhAaGoodO3a88Fhubm748ssvxeYR6wuqajcrKwtP\nnz5FTk4OjI2NReWLFy8Wu6bC+dMUodeDDf/2t79h8eLFCp9eWBmYGqzjMHPmTPz73//GggULcOHC\nBdy9e1fuvvHK4uvrC19fX9jZ2aG6ulo03xDpndjYWMTGxqo6jH7B3d0d7u7uqg6j3/H29oa3t3ef\ntqmSx1mqWsOA1nFQDnU6F0KIbFSSRAbSGgbKok7XQJ3OhRAiG6UlkW+++QZ/+MMfwOPxYGBgAEdH\nR9TX10tdwyAxMRF6enrQ0NDAK6+8AnNzc2hpaUFPTw8vv/wyXFxcMHr0aHC5XBgZGYmt4tVT6r6O\nQ387F1lduXIF9vb2MDQ0BJfLhaOjIy5cuAAAePvtt0XvV2xtbfHjjz8CAN544w3weDwYGhri1KlT\nAJ71ivn73/8OKysr6OrqYvLkyUhPTwfwrI89j8eDvr4+KisrsX79elhaWkpdApUQ0kOd+/zK06+7\nqKiIAWD79+9njDHW2NjIDAwMWHx8POPz+ay8vJwtWbKEVVVVMcYY8/X1Zba2tmLH2Lx5MwPArl+/\nzpqamlh1dTVbsGABA8DOnj3LqqqqWFNTEwsNDWUAWEFBgUwxMsZYaWkpA8D27NkjKouKimIA2MWL\nF1ldXR2rrKxkLi4uTE9Pj7W2torqBQcHMz09PXbnzh3W0tLCCgsL2YwZM5i+vj57+PChqN7KlSuZ\nubm5WLs7d+5kAETn39U1OHPmDNPX12fR0dEvPJf58+czAOzJkyf98lwYY8zW1pYZGhq+8FwYY+z4\n8eNsy5YtrKamhv3+++9s5syZYn3ZfX192ZAhQ9jjx4/F9luxYgU7deqU6N9/+9vfmI6ODjtx4gR7\n8uQJi4yMZBoaGiw/P1/sGoWFhbE9e/awJUuWsH//+989irE/jBMZaGjcmfro03EiDx48QH19PRwc\nHMDlcmFubo6MjAwMHz78hfva29uDx+Nh2LBhWL58OQDAysoKw4cPB4/HE/XyUfS01+q0jkN/OBdZ\n+fn5YfPmzTA2NoaJiQm8vLzw+++/i+YvWrNmDTo6OsTiq6+vR35+Pjw8PAA8G8mdnJwMHx8f+Pr6\nwsjICBs3boSWlpbEecXFxeG9995DRkYGJkyY0HcnSoiaUcpU8DY2NjAzM0NgYCDCwsIQFBSEsWPH\nynwc4XoKz8/dL+z3rMzJ5dRpHYeBei7Cn7NwYN28efMwbtw4HD58GJGRkeBwOEhLS0NAQIBogaC7\nd++iubkZkyZNEh1HV1cXI0aMUNh5nThxQmxtbdIzdM3Ug5+fn0SZUpKIrq4uLl26hI8++ggxMTGI\njo7G0qVLkZqaqvRpifuaOq3joMpzOXv2LHbu3InCwkLU19dLJD0Oh4PVq1dj3bp1uHjxIv70pz/h\nf//3f/Hll1+K6jQ1NQEANm7ciI0bN4rtr6h1HmbOnNmjye/IM1evXkViYqLovRQZuITzu3WmtEWp\nHBwccPr0aVRVVSEhIQFxcXFwcHDoV0tu9pY6rePQ1+eSm5uLf/3rX/jggw/w8OFD+Pj4YMmSJTh8\n+DBGjhyJPXv2SHSgCAoKQmRkJD799FOMHj0aBgYGGDNmjGi7cP2H3bt3Y+3atUqJe9SoURLrl5Pu\nJSYm0jVTA8ePH5darpQkUlZWhtraWtjb28PU1BQ7duzAV199hTt37iijOZVRp3Uc+vpc/vWvf0FP\nTw/AszWg29raEBISAhsbGwDSH38YGxtj2bJlSEtLg76+PlatWiW2XdiDr6CgQCkxE0IkKeXFellZ\nGVavXo2ff/4Zra2t+PHHH/Hrr7+KvqCkrWEwEKjTOg7KPpeutLW1oaKiAjk5OaIkIpzW+uuvv0ZL\nSwuKiorEuhs/b82aNXj69CnOnDkjMWiUy+XijTfewNGjR5GcnIz6+np0dHTg0aNH+O2332S9RISQ\nnujcXUvWLnmffPIJMzc3ZwCYnp4eW7JkCXvw4AGbNWsWMzY2ZkOGDGEjR45kUVFRrL29nTHG2I0b\nN9iYMWOYrq4uc3Z2ZhEREYzH4zEAbOzYsezKlSssLi6OGRoaMgDM3NycffnllywtLU3UlrGxMTt6\n9GiP49yzZw8bMWIEA8B4PB7z8vJi+/btE7X70ksvsZKSEnbw4EFmYGDAALAxY8awX375hTH2rFus\nlpYWs7S0ZJqamszAwIAtXryYlZSUiLXz+++/s7lz5zIul8usra3Z+++/zzZs2MAAMDs7O1EX2s7X\noLy8nJ07d47p6+uz7du3d3ke165dYw4ODkxDQ4MBYCNGjGAxMTH96lz279/PbG1tGYBuPydPnhS1\nFR4ezkxMTJiRkRHz9/dne/fuZQCYra2tWLdjxhibNm0ai4iIkHp9nj59ysLDw5mVlRXT1NRkpqam\nzNfXlxUWFrL4+Himq6vLALDRo0fLPKU4dfGVHXXxVR9d/f5zGBOfUOrYsWNYtmyZWswzpUirV6/G\n8ePH8fvvv6s6lF4b6Ofi6emJvXv3wtrauk/b9ff3B9D1s2Eiib5P1EdXv/80FbwM1Gkdh4F0Ls8/\nHrt16xa4XG6fJxBCiHQDOon8/PPPoukwuvuoYlEYojjh4eEoKirCL7/8gjfeeAPbtm1TdUhEiVav\nXi329yttGYGvv/4aEREREAgE8PHxgZWVFbhcLiwtLeHt7Y1bt271Oo6WlhZMmDBBors48Gwapdmz\nZ4PH48HCwgLh4eF4+vSpXO1s375d6vfW8+OdAODVV1/t8jtu6NChAIBTp04hPj5e4j+JmZmZYvV7\nMvC7pwZ0EpkwYYLYHPldfdLS0nrVjjqt4zAQz4XH42HChAn405/+hC1btsDe3l7VIRElMzExQXZ2\nNu7evYuUlBSxbZs3b0ZSUhIiIyMhEAhw5coVHDlyBDU1NcjLywOfz8ecOXNQVlbWqxiioqKkzqtW\nWFgId3d3uLm5oaqqCidPnsThw4exZs2aXrXXG87OzgAALy8vcLlcuLm5oba2VrTd29sbjx49Qm5u\nrmiGB4Xp/JKEXoQRIl1/eLHe3NzMnJycBkwbilxjnTHGduzYwcaNG8f4fD5jjLG2tjb25z//WazO\n999/zwCwmJgY+YJmjH377bfM3d2dAWBRUVFi25YtW8asra2ZQCAQle3cuZNxOJwez8P2vG3btvWo\nk8f8+fNZfX29RHlwcDC7ePGiWFloaChzcnJibW1tEvVpjXVCBrG+mHa/v07tX1xcjE2bNmHr1q3g\ncrkAno1l6rxSqXCsUUlJiVzt8Pl8bNiwAYmJiRLb2tvbcfbsWbi6uoqNZVq4cCEYY8jKypKrzZ44\nf/489PX1xcpKS0vx008/Yd68eWLlW7ZsQUFBgdRzUDRKIoQoEWMMCQkJoskujY2NsXjxYrG5vHoz\n7f5AWKZAUZKSksAYg5eXV7f1+Hw+AMDAwECudqKiovDuu++KZkB43r1799DY2Cga2yRka2sLAAp5\nFyOLuLg4hIWFSZQbGxvD1dUViYmJSu8ZR0mEECXasmULIiIiEBUVhcrKSuTm5qK0tBQuLi6oqKgA\n8OzLsfO0IPv27cPWrVvFyhITE7Fo0SLY2tqCMYbi4mKEhoYiKCgIzc3NCAsLw4MHD3Djxg20t7fj\ntddeQ2lpaa/bAP7bm08gECju4sjo7NmzGD9+PHg8Xrf1vv/+ewD/fU8gi2+//RYlJSVYsWKF1O3C\npZ473xFwuVzo6uqKfqayioiIgLGxMbS1tWFtbY3FixcjPz+/230eP36MnJwc+Pr6St0+bdo0PH78\nGDdv3pQrpp6iJEKIkvD5fCQkJGDJkiUIDAyEoaEhHB0dceDAAVRXV+PgwYMKa2ugLFMgr6amJty/\nf1/0P35pKioqkJaWhrCwMDg5Ob3wjqUzPp+PtWvXIjk5ucs6wh5Ywpmjn6elpSW6C5LF66+/jlOn\nTqG0tBSNjY04evQoHj58CFdXVxQWFna5X1xcHN5//31oaEj/Gn/ppZcAPJtWSJkoiRCiJIWFhWhs\nbMT06dPFymfMmAFtbe0up3ZRhP42tX9vVVZWgjHW7V2Ik5MTwsLCsHjxYmRnZ4uWE+ipyMhIvPPO\nO7C0tOyyjvBdzPPLUwi1trbKNUv56NGjMW3aNAwdOhTa2tqYOXMmUlNTwefzsW/fPqn7lJWV4dSp\nU2LTFHUmvFby3h31lNJm8SVksBN2sRT24X+ekZERGhoalNq+Oi1T0NLSAuDZOXXFzMwMKSkpcHBw\nkPn4eXl5uH37NhISErqtJ3ynVF9fL1be3NyMlpYWhS054OjoiCFDhuCXX36Ruj0+Ph6rVq0SJTVp\nhAlNeO2Uhe5ECFESIyMjAJCaLJQ97b46LVMA/PcLsbuZFkxNTUXXXFYpKSm4ePEiNDQ0RAPyhC/W\nY2JiwOFw8MMPP8Da2hr6+voSE5EK3x1NnjxZrvY7EwgEEAgEUpNmeXk5jhw5gpCQkG6P0draCgBK\nX8OJkgghSjJp0iQMHToUP/zwg1j59evX0draildeeUVUpuhp99VpmQLg2V0Gh8NBXV1dl3VOnz7d\n7aOo7qSmpkoMUhbexUVFRYExhunTp0NTUxMeHh7Izc0V62SQnZ0NDocj83sYAJg/f75EWX5+Phhj\ncHJyktgWHx+PwMBAmJiYdHtc4bUyNzeXOSZZUBIhREm4XC7Wr1+PkydP4osvvkB9fT1u376NNWvW\nwMLCAsHBwaK6vZ12X52WKZCGx+PBxsYGjx49krq9uLgY5ubmWLZsmcS2gIAAmJub48aNGwqJZdOm\nTaioqMDmzZvR1NSEq1evYufOnQgKCsL48eNlbvfx48dIS0tDbW0t2tracPXqVbz99tuwsrKSGAVf\nUVGBw4cP92h1TeG1cnR0lOMse46SCCFKtHnzZsTGxiI6OhrDhw+Hq6srxo4dK7aeCgCEhIRg7ty5\nWL58OcaPH49t27aJHkM4OTmJuuquWbMGZmZmsLe3h4eHB2pqagA8e+7t6OgIXV1duLi4YNy4cbh8\n+bLY45DetqFqnp6eKCwslNoDqruxEK2traisrFTYQEAHBwdcuHABX331FYYNGwZfX1+8+eab2L9/\nv1ztLliwABs3bsSoUaPA4/GwdOlSzJ49G9euXcOwYcPE6n788cfw8vKSGKciTX5+PiwtLRX2iK1L\nnYew07QnhEjXH6Y9kSY4OJiZmJioOgypFDntSVFREdPU1JR5HZiOjg7m4uLCUlJSZNqvt1TVLmOM\nVVdXMy6Xy3bt2iWxjaY9IYRIGEhT+/cEn8/HhQsXUFRUJHpBbGdnh+joaERHR6OxsbFHx+no6EBm\nZiYaGhr6dDZvVbUrtGXLFkydOhWhoaEAnt2plZWVIS8vT9QJQFEoiRBC+p2amhosWLAA48aNw5tv\nvikqj4iIgL+/PwICArp9yS6Uk5ODjIwMZGdnv3CkuyKpql0ASEhIQEFBAc6dOycaK5OVlQVLS0u4\nuLjg7NmzCm2PkgghA9hAnNr/RQ4cOCDWS+qLL74Q2x4TE4PQ0FDs2LHjhcdyc3PDl19+KTZnWF9Q\nVbtZWVl4+vQpcnJyYGxsLCpfvHix2DUVzpWmCDTYkJABLDY2FrGxsaoOo8+5u7vD3d1d1WH0O97e\n3vD29u7TNulOhBBCiNwoiRBCCJEbJRFCCCFyoyRCCCFEbl2+WD927FhfxkFIvyecRoL+Nnru6tWr\nAOiaqYNHjx5Jn9Cz8+hD4QhT+tCHPvShD32e/0gbsc5hTMkL8BIygHE4HKSnp0ssLUsIeYbeiRBC\nCJEbJRFCCCFyoyRCCCFEbpRECCGEyI2SCCGEELlREiGEECI3SiKEEELkRkmEEEKI3CiJEEIIkRsl\nEUIIIXKjJEIIIURulEQIIYTIjZIIIYQQuVESIYQQIjdKIoQQQuRGSYQQQojcKIkQQgiRGyURQggh\ncqMkQgghRG6URAghhMiNkgghhBC5URIhhBAiN0oihBBC5EZJhBBCiNwoiRBCCJEbJRFCCCFyoyRC\nCCFEbpRECCGEyI2SCCGEELlREiGEECI3SiKEEELkRkmEEEKI3CiJEEIIkRuHMcZUHQQh/UFwcDDu\n3r0rVnbjxg1YW1vD2NhYVDZkyBD885//xKhRo/o6REL6HU1VB0BIf2Fubo6DBw9KlN+6dUvs3zY2\nNpRACPkPepxFyH+sWLHihXW0tbURFBSk/GAIGSDocRYhz5k0aRLu3LmD7v4s7t69i3HjxvVhVIT0\nX3QnQshz/vrXv2LIkCFSt3E4HEyZMoUSCCHPoSRCyHOWL1+Ojo4OqduGDBmC119/vY8jIqR/o8dZ\nhHQya9YsXL9+HQKBQKycw+GgtLQUlpaWKoqMkP6H7kQI6eQvf/kLOByOWJmGhgacnZ0pgRDSCSUR\nQjrx9/eXKONwOPjrX/+qgmgI6d8oiRDSyfDhw+Hm5ib2gp3D4cDHx0eFURHSP1ESIUSKwMBAUTff\nIUOGYP78+Rg2bJiKoyKk/6EkQogUS5Ysgba2NgCAMYbAwEAVR0RI/0RJhBAp9PT08Oc//xnAs1Hq\nixYtUnFEhPRPlEQI6cLKlSsBAD4+PtDT01NxNIT0T2o3TqRz10xCCOlP0tPTsXTpUlWHoTBqOYvv\n2rVr4eTkpOowiAIsW7ZMpT/PL774AgEBAdDUHDh/Krt37wYAfPDBByqOhHS2bNkyVYegcGp5J6Ju\nmX4wU/XPs6WlBVwuVyVty0s4zuX48eMqjoR0purfZ2WgdyKEdGOgJRBC+holEUIIIXKjJEIIIURu\nlEQIIYTIjZIIIYQQuVESIYPCuXPnYGhoiNOnT6s6lH7v66+/RkREBAQCAXx8fGBlZQUulwtLS0t4\ne3vj1q1bvW6jpaUFEyZMwMaNGyW25eXlYfbs2eDxeLCwsEB4eDiePn0qVzvbt28Hh8OR+EyaNEms\n3quvviq1HofDwdChQwEAp06dQnx8fJeLlg1WlETIoKBmPdmVZvPmzUhKSkJkZCQEAgGuXLmCI0eO\noKamBnl5eeDz+ZgzZw7Kysp61U5UVBTu3r0rUV5YWAh3d3e4ubmhqqoKJ0+exOHDh7FmzZpetdcb\nzs7OAAAvLy9wuVy4ubmhtrZWZfH0N5REyKDg6emJurq6fjEHFp/Px6xZs1QdhoS4uDikpaXh2LFj\n0NfXBwA4OTnB2dkZPB4P1tbWiImJQV1dHT777DO52/nuu+/w008/Sd22bds2jBgxAlu3boWenh6c\nnJwQHh6Ozz77DD///LNc7X3++edgjIl9OrfP5XJRX18vUS84OBgffvihqKZsUMcAACAASURBVF5Y\nWBimTJkCDw8PtLe3yxWPuqEkQkgfS0lJQWVlparDEFNcXIxNmzZh69atorExmpqaEo//bGxsAAAl\nJSVytcPn87FhwwYkJiZKbGtvb8fZs2fh6uoqNn3RwoULwRhDVlaWXG32xPnz50WJU6i0tBQ//fQT\n5s2bJ1a+ZcsWFBQUSD2HwYiSCFF7eXl5sLKyAofDwd69ewEAycnJ0NPTA4/HQ1ZWFhYuXAgDAwOM\nGjUKR48eFe2blJQELpcLMzMzrF69GhYWFuByuaJ12IVCQ0Ohra2NESNGiMreffdd6OnpgcPhoLq6\nGsCzKXnWr1+PkpIScDgc2NnZAXj2JWZgYICYmJi+uCQSkpKSwBiDl5dXt/X4fD4AwMDAQK52oqKi\n8O6778LU1FRi271799DY2AgrKyuxcltbWwBQyLsYWcTFxSEsLEyi3NjYGK6urkhMTKTHpKAkQgYB\nZ2dnfPfdd2JlISEh+OCDD8Dn86Gvr4/09HSUlJTAxsYGq1atQltbG4BnySEoKAjNzc0ICwvDgwcP\ncOPGDbS3t+O1115DaWkpgGdfwp2nsti3bx+2bt0qVpaYmIhFixbB1tYWjDEUFxcDgOhlrUAgUMo1\neJGzZ89i/Pjx4PF43db7/vvvAfz3PYEsvv32W5SUlGDFihVSt5eXlwOAxB0Bl8uFrq4uKioqZG4T\nACIiImBsbAxtbW1YW1tj8eLFyM/P73afx48fIycnB76+vlK3T5s2DY8fP8bNmzflikmdUBIhg96s\nWbNgYGAAU1NTBAQEoKmpCQ8fPhSro6mpiYkTJ0JHRwf29vZITk5GQ0MDUlNTFRKDp6cn6uvrsWnT\nJoUcTxZNTU24f/++6H/80lRUVCAtLQ1hYWFwcnJ64R1LZ3w+H2vXrkVycnKXdYQ9sJ5fllhIS0tL\ndBcki9dffx2nTp1CaWkpGhsbcfToUTx8+BCurq4oLCzscr+4uDi8//770NCQ/hX50ksvAQBu374t\nc0zqhpIIIc8RrmYovBPpyvTp08Hj8eR+2dufVFZWgjHW7V2Ik5MTwsLCsHjxYmRnZ0NLS0umNiIj\nI/HOO+/A0tKyyzrCdzHSXli3trZCV1dXpjYBYPTo0Zg2bRqGDh0KbW1tzJw5E6mpqeDz+di3b5/U\nfcrKynDq1CkEBQV1eVzhtZL37kidDJz5rQnpZ3R0dFBVVaXqMHqtpaUFwLPz6YqZmRlSUlLg4OAg\n8/Hz8vJw+/ZtJCQkdFtP+D6pvr5erLy5uRktLS2wsLCQuW1pHB0dMWTIEPzyyy9St8fHx2PVqlXd\nTr4pTGjCazeY0Z0IIXJoa2tDbW0tRo0apepQek34hdjdIDpTU1MYGRnJdfyUlBRcvHgRGhoaogF8\nwhfrMTEx4HA4+OGHH2BtbQ19fX38+uuvYvsL3xtNnjxZrvY7EwgEEAgEUpNmeXk5jhw5gpCQkG6P\n0draCgBy3R2pG0oihMghJycHjDHMnDlTVKapqfnCx2D9kZmZGTgcDurq6rqsc/r06W4fRXUnNTVV\nYvyF8A4uKioKjDFMnz4dmpqa8PDwQG5urlgHg+zsbHA4HJnfwwDA/PnzJcry8/PBGJO60Fl8fDwC\nAwNhYmLS7XGF18rc3FzmmNQNJRFCekAgEODJkydob2/HrVu3sHbtWlhZWYk9N7ezs0NNTQ0yMzPR\n1taGqqoqif9VA4CJiQnKysrw4MEDNDQ0oK2tDdnZ2Srr4svj8WBjY4NHjx5J3V5cXAxzc3Opq/IF\nBATA3NwcN27cUEgsmzZtQkVFBTZv3oympiZcvXoVO3fuRFBQEMaPHy9zu48fP0ZaWhpqa2vR1taG\nq1ev4u2334aVlZXEKPiKigocPny4RytCCq+Vo6OjHGepXiiJELW3d+9ezJgxAwAQHh4Ob29vJCcn\ni5aRnTx5Mu7du4dDhw5h/fr1AIAFCxagqKhIdIyWlhY4OjpCV1cXLi4uGDduHC5fviz2SCQkJARz\n587F8uXLMX78eGzbtk30uMPJyUnUHXjNmjUwMzODvb09PDw8UFNT0yfXoTuenp4oLCyU2gOqu7EQ\nra2tqKysVNhAQAcHB1y4cAFfffUVhg0bBl9fX7z55pvYv3+/XO0uWLAAGzduxKhRo8Dj8bB06VLM\nnj0b165dw7Bhw8Tqfvzxx/Dy8pIYpyJNfn4+LC0tFfaIbUBjagYAS09PV3UYREH6w88zODiYmZiY\nqDQGWfj5+TE/Pz+Z9ikqKmKamprs888/l2m/jo4O5uLiwlJSUmTar7dU1S5jjFVXVzMul8t27dol\n87794fdZ0ehOhJAeUPeZW+3s7BAdHY3o6Gg0Njb2aJ+Ojg5kZmaioaEBAQEBSo5Q9e0KbdmyBVOn\nTkVoaGift90fDeoksmvXLtFLxQMHDqg6nC5lZGTAxsZG1LNlxIgRCAwMfOF+N2/eREBAAKytraGj\no4Phw4djypQp2L59u6hOQEBAl1Ngd/6cOXNGIpYXDY5LSEgAh8OBhoYGJkyYgNzc3F5fD6IcERER\n8Pf3R0BAQLcv2YVycnKQkZGB7OzsF450VyRVtQs8+30uKCjAuXPnZB4ro7ZUfSukaJDxdrGoqIgB\nYPv371diVIpha2vLDA0Ne1T31q1bjMfjsbCwMHb//n3G5/PZ3bt32Ycffsjc3NxE9ZYtW8a++uor\nVltby9ra2thvv/3GADAvLy/W2trKmpqaWGVlJVu1ahU7ffq0WCwA2IgRI1hra6vUGNrb29mYMWMY\nALE2ZSHrz1PRIiIimLa2NgPAxo4dy44fP66yWHpKnsdZz7tw4QILDw9XYETqITMzk8XGxrL29na5\nj6Hq32dlGNR3IvLor9N4d7Zr1y4YGRkhMTERY8eOBZfLxbhx48Re9gIAh8PB7NmzYWhoCE1NTbFy\nLS0t8Hg8mJqa4pVXXpFo45VXXkF5eTkyMzOlxpCRkSF3t9D+IjY2Fk+fPgVjDPfv34efn5+qQ1I6\nd3d3xMXFqTqMfsfb2xsRERFSp2UZzCiJyKg/TuMtze+//466ujqJnj/a2tpi03sfPXq0R48EgoOD\n8ec//1msTDggq3PPGaGEhARRbydCiHqiJCLFN998gz/84Q/g8XgwMDCAo6Mj6uvrpU7jnZiYCD09\nPWhoaOCVV16Bubk5tLS0oKenh5dffhkuLi4YPXo0uFwujIyMxBa4AZQ3BfiMGTPQ1NSEefPm4dtv\nv1XosYXmzZuHiRMn4vLlyxKr1H377bdobm6Gu7u7UtomhPQPlEQ6aWpqgpeXF/z8/FBTU4OioiKM\nGzcOra2tUqfxXrt2LTZs2ADGGPbv34/79++jvLwcc+bMwY8//oiIiAj8+OOPqKmpweuvv46dO3eK\nTR+trCnAP/zwQ0yfPh03b96Es7MzHBwc8PHHHyt8TMLq1asBQKJjwieffIJ169YptC1CSP9DSaST\nBw8eoL6+Hg4ODuByuTA3N0dGRgaGDx/+wn3t7e3B4/EwbNgwLF++HABgZWWF4cOHg8fjiXpUPT/z\nq7KmANfV1cV3332H//mf/8GECRNw584dhIeHY+LEifjmm28U1s7rr78OPT09/POf/xQNVLt37x7y\n8/O7XDeCEKI+aBbfTmxsbGBmZobAwECEhYUhKCgIY8eOlfk4winFn5/WWtglsK/mV9LS0kJoaChC\nQ0Nx/fp1xMXFITMzE/7+/rh79y6MjY173YahoSFWrFiBQ4cOIS0tDW+88QZ2796NkJAQaGtriyaq\n642rV6/2+hiDiXBKjmPHjqk4EjIYUBLpRFdXF5cuXcJHH32EmJgYREdHY+nSpUhNTR3QM3b+8Y9/\nxP/93/8hJCQE+/fvx+XLl7FkyRKFHDskJASHDh3CgQMH4OPjg+PHj+Pf//63Qo4NPFsNkNazlp20\nua4IUTR6nCWFg4MDTp8+jbKyMoSHhyM9PR27du1SdVjdys3NFc0FBQC+vr5SF/f5y1/+AuDZGg2K\nMnXqVMycORPff/89goOD4e/vr5C7HKH09HSJWWDp0/XHz88Pfn5+Ko+DPpIfdURJpJOysjLcuXMH\nwLM1FHbs2IGXX35ZVNZf/etf/4Kenp7o30+fPpUas7AXlaInjhN29z1x4kSPZkElhKgHSiKdlJWV\nYfXq1fj555/R2tqKH3/8Eb/++qto3Qhp03j3Rm+nAG9ra0NFRQVycnLEkggA+Pj44NixY6itrUVd\nXR2ysrLw0UcfwdvbW+FJZOnSpRg+fDh8fHxgY2Oj0GMTQvoxpmYgw7QCn3zyCTM3N2cAmJ6eHluy\nZAl78OABmzVrFjM2NmZDhgxhI0eOZFFRUaKpDm7cuMHGjBnDdHV1mbOzM4uIiGA8Hk80LcaVK1dY\nXFwcMzQ0ZACYubk5+/LLL1laWpqoLWNjY3b06FHGGGPnzp1j+vr6bPv27V3GefLkSdE0I919Tp48\nKdrnq6++YsuWLWO2trZMR0eHaWtrs/Hjx7MtW7awlpYWiTbq6+vZnDlzmImJCQPANDQ0mJ2dHYuJ\niekyluHDh7P33ntPtO3DDz9k3333nejfGzduZCNGjBAdz97enl25cqVHPxshWX6e5JneTntClEcd\nf585jKnXgzoOh4P09HQsXbpU1aEQBaCfp+z8/f0BAMePH1dxJKQzdfx9psdZhBBC5EZJhBBCiNwo\niRBC5PL1118jIiICAoEAPj4+sLKyApfLhaWlJby9vXHr1i25jy0QCLB79+4uZ8yOjo6Gvb09DAwM\noKOjAzs7O3z44YdSF9Q6cuQIZsyYAX19fYwZMwZvvPEGysvLRdtPnTqF+Ph4tV94TFkoiRBCZLZ5\n82YkJSUhMjISAoEAV65cwZEjR1BTU4O8vDzw+XzMmTMHZWVlMh+7qKgIc+bMwbp167ocz3Tp0iW8\n9957ePDgAaqrqxEbG4vExETR+yCh9PR0rFy5Ev7+/nj06BGysrKQm5uLhQsXisZReXl5gcvlws3N\nDbW1tbJfjEGOkggh3eiL9WMGyho1QnFxcUhLS8OxY8egr68PAHBycoKzszN4PB6sra0RExODuro6\nfPbZZzId++bNm/joo4+wZs0aTJ06tct6Q4cORXBwMExMTKCvr4+lS5fCx8cH58+fR2lpqajeP/7x\nD4wcORIbNmyAoaEhpk6dinXr1qGgoADXr18X1QsLC8OUKVPg4eEhdZAu6RolEUK60RfrxwyUNWoA\noLi4GJs2bcLWrVvB5XIBAJqammJr1AAQjRUqKSmR6fhTpkxBRkYGVq5cCR0dnS7rnTlzRmJxKOEk\nqc/fvZSWlsLCwgIcDkdUNnr0aADAr7/+Krb/li1bUFBQQFPsyIiSCFErjDEkJCRg4sSJ0NHRgbGx\nMRYvXiw2c3JoaCi0tbUxYsQIUdm7774LPT09cDgcVFdXA4DU9WOSkpLA5XJhZmaG1atXw8LCAlwu\nF7NmzRL7n21v2gCUt85MbyUlJYExBi8vr27rCWd0NjAw6IuwAACPHz+Grq4urK2tRWU2NjYSCVr4\nPqTzoFhjY2O4uroiMTFRbacoUQqVjlJRAqjhYJ7BTNaf59///nemra3NPv/8c1ZbW8tu3brFXn75\nZTZ8+HBWXl4uqrdy5Upmbm4utu/OnTsZAFZVVSUq8/X1Zba2tmL1goODmZ6eHrtz5w5raWlhhYWF\nbMaMGUxfX589fPhQIW2cOXOG6evrs+jo6B6fu5AyBxva2Ngwe3v7F9bLyMhgANiJEyfkbuuPf/wj\nmzJlSo/qNjU1MX19fRYaGipWnpOTw7S0tFhSUhKrr69nP/30E5s4cSKbP3++1ONEREQwAOzHH3+U\nO+7uqOP3E92JELXB5/ORkJCAJUuWIDAwEIaGhnB0dMSBAwdQXV2NgwcPKqwtTU1N0d2Ovb09kpOT\n0dDQgNTUVIUcX1nrzPRGU1MT7t+/D1tb2y7rVFRUIC0tDWFhYXBycnrhHYuixMbGwsLCAtu3bxcr\nd3V1RXh4OEJDQ2FgYIBJkyahoaEBn376qdTjvPTSSwCA27dvKz1mdUFJhKiNwsJCNDY2Yvr06WLl\nM2bMgLa2ttjjJkWbPn06eDye2GMzdVNZWQnGGHg8Xpd1nJycEBYWhsWLFyM7O1u0ho4ynTx5EseO\nHcOFCxdEL/qFoqKicPDgQVy8eBGNjY24d+8eZs2aBScnJ7EX8ELCc6uoqFB63OqCkghRG8LumUOH\nDpXYZmRkhIaGBqW2r6Ojg6qqKqW2oUotLS0A0O0LbzMzM1y6dAl79uyBoaGh0mNKS0tDXFwccnJy\nJBaP++233xAfH4933nkH8+bNg56eHqytrXHo0CGUlZVh586dEscTrhkkPFfyYrQoFVEbRkZGACA1\nWdTW1mLUqFFKa7utrU3pbaia8Au2u0F5pqamop+Dsu3ZswcXLlzApUuXpP7HoaioCB0dHRg5cqRY\nuYGBAUxMTFBYWCixj3AlzoG8AF1foyRC1MakSZMwdOhQ/PDDD2Ll169fR2trK1555RVRmaampkKX\nKc7JyQFjTLRkgDLaUDUzMzNwOBzU1dV1WadzV19lYIzho48+wpMnT5CZmQlNTelfY8KE/ttvv4mV\nNzQ0oKamRtTV93nCczM3N1dw1OqLHmcRtcHlcrF+/XqcPHkSX3zxBerr63H79m2sWbMGFhYWCA4O\nFtW1s7NDTU0NMjMz0dbWhqqqKolxA0DX68cIBAI8efIE7e3tuHXrFtauXQsrKysEBQUppI3erjOj\nDDweDzY2NqI13DsrLi6Gubm51GV5AwICYG5ujhs3bvQ6jjt37uDjjz/GoUOHoKWlBQ6HI/YRrkJq\nbW2NuXPn4tChQ8jNzQWfz0dpaano9+Ctt96SOLbw3BwdHXsd52BBSYSolc2bNyM2NhbR0dEYPnw4\nXF1dMXbsWIlFu0JCQjB37lwsX74c48ePx7Zt20SPMJ5/6bpmzRqYmZnB3t4eHh4eqKmpAfDsmbmj\noyN0dXXh4uKCcePG4fLly2LvC3rbRn/k6emJwsJC0TiQ57Fuxla0traisrISWVlZ3R7/2rVrcHZ2\nxsiRI3H9+nXcvHkTFhYWmD17NnJzc1/YzvM4HA6OHz+OgIAAvPXWWzA2Noa9vT0ePnyIjIwMuLi4\nSOyTn58PS0tLhS/aptZU2sFYCaCG/bAHs/748wwODmYmJiaqDqNLyhwnUlRUxDQ1Ndnnn38u034d\nHR3MxcWFpaSkKCUuRaiurmZcLpft2rVLaW30x9/n3qI7EULkMFhnfLWzs0N0dDSio6OlzpgrTUdH\nBzIzM9HQ0ICAgAAlRyi/LVu2YOrUqQgNDVV1KAMKJRFCiEwiIiLg7++PgICAbl+yC+Xk5CAjIwPZ\n2dndjjFRpYSEBBQUFODcuXN9MrZFnVASIUQGkZGRSE1NRV1dHaytrXHixAlVh6QSMTExCA0NxY4d\nO15Y183NDV9++aXYPGL9SVZWFp4+fYqcnBwYGxurOpwBh7r4EiKD2NhYxMbGqjqMfsHd3R3u7u6q\nDqPXvL294e3treowBiy6EyGEECI3SiKEEELkRkmEEEKI3CiJEEIIkZtavljfvXs3jh8/ruowiILQ\nz1M2165dAwD4+/urOBIyGHAYU691IOkPhyhSdnY2pk2b1m+7p5KBZ926dXByclJ1GAqjdkmEEEXi\ncDhIT0/H0qVLVR0KIf0SvRMhhBAiN0oihBBC5EZJhBBCiNwoiRBCCJEbJRFCCCFyoyRCCCFEbpRE\nCCGEyI2SCCGEELlREiGEECI3SiKEEELkRkmEEEKI3CiJEEIIkRslEUIIIXKjJEIIIURulEQIIYTI\njZIIIYQQuVESIYQQIjdKIoQQQuRGSYQQQojcKIkQQgiRGyURQgghcqMkQgghRG6URAghhMiNkggh\nhBC5URIhhBAiN0oihBBC5EZJhBBCiNwoiRBCCJEbJRFCCCFyoyRCCCFEbpRECCGEyI2SCCGEELlp\nqjoAQvqL2tpaMMYkypuamvDkyROxsqFDh0JLS6uvQiOk3+IwaX81hAxC8+bNw+XLl19Yb8iQIXj8\n+DHMzc37ICpC+jd6nEXIfyxfvhwcDqfbOhoaGpgzZw4lEEL+g5IIIf/h5+cHTc3un/ByOBz89a9/\n7aOICOn/KIkQ8h/GxsZwd3fHkCFDuqyjoaEBHx+fPoyKkP6NkgghzwkMDIRAIJC6TVNTE56enjA0\nNOzjqAjpvyiJEPIcLy8v6OjoSN3W0dGBwMDAPo6IkP6Nkgghz+HxePDx8ZHafVdXVxceHh4qiIqQ\n/ouSCCGdrFixAm1tbWJlWlpa8PPzg66uroqiIqR/oiRCSCfz58+XeO/R1taGFStWqCgiQvovSiKE\ndKKlpYWAgABoa2uLyoyMjODm5qbCqAjpnyiJECLF8uXL0draCuBZUgkMDHzhGBJCBiOa9oQQKQQC\nAUaOHImKigoAQF5eHmbPnq3iqAjpf+hOhBApNDQ08Je//AUAYGFhgVmzZqk4IkL6p0Fzf/7o0SN8\n9913qg6DDCDDhw8HAPzxj3/E8ePHVRwNGUhGjx4NJycnVYfRJwbN46xjx45h2bJlqg6DEDII+Pn5\nDZr/eAyaOxGhQZIzBzV/f38AUMgf8YkTJ+Dn59fr4/R3wv9k0d9H7wl//wYLeidCSDcGQwIhpDco\niRBCCJEbJRFCCCFyoyRCCCFEbpRECCGEyI2SCCGEELlREiGkC+fOnYOhoSFOnz6t6lD6va+//hoR\nEREQCATw8fGBlZUVuFwuLC0t4e3tjVu3bsl9bIFAgN27d3c5a0B0dDTs7e1hYGAAHR0d2NnZ4cMP\nP0RjY6NE3SNHjmDGjBnQ19fHmDFj8MYbb6C8vFy0/dSpU4iPj0dHR4fc8Q42lEQI6QKNmeiZzZs3\nIykpCZGRkRAIBLhy5QqOHDmCmpoa5OXlgc/nY86cOSgrK5P52EVFRZgzZw7WrVuH5uZmqXUuXbqE\n9957Dw8ePEB1dTViY2ORmJgoMV4jPT0dK1euhL+/Px49eoSsrCzk5uZi4cKFaG9vB/BsZUsulws3\nNzfU1tbKfjEGIUoihHTB09MTdXV1WLRokapDAZ/P75fzd8XFxSEtLQ3Hjh2Dvr4+AMDJyQnOzs7g\n8XiwtrZGTEwM6urq8Nlnn8l07Js3b+Kjjz7CmjVrMHXq1C7rDR06FMHBwTAxMYG+vj6WLl0KHx8f\nnD9/HqWlpaJ6//jHPzBy5Ehs2LABhoaGmDp1KtatW4eCggJcv35dVC8sLAxTpkyBh4eHKLmQrlES\nIWQASElJQWVlparDEFNcXIxNmzZh69at4HK5AABNTU2Jx382NjYAgJKSEpmOP2XKFGRkZGDlypVd\nrnsPAGfOnMGQIUPEyoTznj1/91JaWgoLCwtwOBxR2ejRowEAv/76q9j+W7ZsQUFBARITE2WKeTCi\nJEKIFHl5ebCysgKHw8HevXsBAMnJydDT0wOPx0NWVhYWLlwIAwMDjBo1CkePHhXtm5SUBC6XCzMz\nM6xevRoWFhbgcrmYNWuW2P94Q0NDoa2tjREjRojK3n33Xejp6YHD4aC6uhoAsHbtWqxfvx4lJSXg\ncDiws7MDAJw/fx4GBgaIiYnpi0siISkpCYwxeHl5dVuPz+cDAAwMDPoiLADA48ePoaurC2tra1GZ\njY2NRCIWvg8RJjohY2NjuLq6IjExkR5rvgAlEUKkcHZ2lpj1OSQkBB988AH4fD709fWRnp6OkpIS\n2NjYYNWqVaJ12UNDQxEUFITm5maEhYXhwYMHuHHjBtrb2/Haa6+JHrEkJSVh6dKlYm3s27cPW7du\nFStLTEzEokWLYGtrC8YYiouLAUD08lcgECjlGrzI2bNnMX78ePB4vG7rff/99wCeXdO+0NzcjEuX\nLmHVqlViq1NGRkaivLwce/bsQUNDAwoLC5GYmIj58+dj5syZEseZNm0aHj9+jJs3b/ZJ3AMVJRFC\n5DBr1iwYGBjA1NQUAQEBaGpqwsOHD8XqaGpqYuLEidDR0YG9vT2Sk5PR0NCA1NRUhcTg6emJ+vp6\nbNq0SSHHk0VTUxPu378PW1vbLutUVFQgLS0NYWFhcHJyeuEdi6LExsbCwsIC27dvFyt3dXVFeHg4\nQkNDYWBggEmTJqGhoQGffvqp1OO89NJLAIDbt28rPeaBjJIIIb0k/N+u8E6kK9OnTwePx8PPP//c\nF2EpVWVlJRhj3d6FODk5ISwsDIsXL0Z2dja0tLSUHtfJkydx7NgxXLhwQfSiXygqKgoHDx7ExYsX\n0djYiHv37mHWrFlwcnISewEvJDw34eqWRDpKIoT0IR0dHVRVVak6jF5raWkBgG5feJuZmeHSpUvY\ns2cPDA0NlR5TWloa4uLikJOTg7Fjx4pt++233xAfH4933nkH8+bNg56eHqytrXHo0CGUlZVh586d\nEsfT1dUF8N9zJdINuvVECFGVtrY21NbWYtSoUaoOpdeEX7DdDcozNTWFkZFRn8SzZ88eXLhwAZcu\nXcLQoUMlthcVFaGjowMjR44UKzcwMICJiQkKCwsl9mltbQXw33Ml0lESIaSP5OTkgDEm9hJXU1Pz\nhY/B+iMzMzNwOBzU1dV1WacvRvozxvDRRx/hyZMnyMzMhKam9K80YeL+7bffxMobGhpQU1Mj6ur7\nPOG5mZubKzhq9UKPswhREoFAgCdPnqC9vR23bt3C2rVrYWVlhaCgIFEdOzs71NTUIDMzE21tbaiq\nqpIYswAAJiYmKCsrw4MHD9DQ0IC2tjZkZ2errIsvj8eDjY0NHj16JHV7cXExzM3NpS5JHRAQAHNz\nc9y4caPXcdy5cwcff/wxDh06BC0tLXA4HLHPrl27AADW1taYO3cuDh06hNzcXPD5fJSWliI4OBgA\n8NZbb0kcW3hujo6OvY5TnVESIUSKvXv3YsaMGQCA8PBweHt7Izk5Gbt37wYATJ48Gffu3cOhQ4ew\nfv16AMCCBQtQVFQkOkZLSwscHR2hq6sLFxcXjBs3DpcvXxZ7jxASS+rqrAAADrlJREFUEoK5c+di\n+fLlGD9+PLZt2yZ6fPL8C981a9bAzMwM9vb28PDwQE1NTZ9ch+54enqisLBQNA7ked2NrWhtbUVl\nZSWysrK6Pf61a9fg7OyMkSNH4vr167h58yYsLCwwe/Zs5ObmvrCd53E4HBw/fhwBAQF46623YGxs\nDHt7ezx8+BAZGRlwcXGR2Cc/Px+WlpaYPHlyj9oYtNggkZ6ezgbR6Q5qfn5+zM/PT6UxBAcHMxMT\nE5XGIAt5/j6KioqYpqYm+/zzz2Xar6Ojg7m4uLCUlBSZ9utL1dXVjMvlsl27dsm8b3/4/etLdCdC\niJKo+0ywdnZ2iI6ORnR0tNQZc6Xp6OhAZmYmGhoaEBAQoOQI5bdlyxZMnToVoaGhqg6l36MkIoO3\n334b+vr64HA4KCgoUHU4MsvIyICNjY3Ec2NtbW2YmZnh1Vdfxc6dO/HkyRNVh0oGiIiICPj7+yMg\nIKDbl+xCOTk5yMjIQHZ29gtHuqtKQkICCgoKcO7cuT4Z2zLQURKRwaeffopDhw6pOgy5+fr64t69\ne7C1tYWhoSEYYxAIBKisrMSxY8dgbW2N8PBwODg44IcfflB1uANWZGQkUlNTUVdXB2tra5w4cULV\nISlVTEwMQkNDsWPHjhfWdXNzw5dffik2X1h/kpWVhadPnyInJwfGxsaqDmdAoC6+gxyHw4GRkRFe\nffVVvPrqq/D09MSyZcvg6emJX375pU8Giamb2NhYxMbGqjqMPuXu7g53d3dVh9Fr3t7e8Pb2VnUY\nAwrdicjo+Wmk1ZGfnx+CgoJQWVmJAwcOqDocQkg/R0mkG4wx7Ny5E+PHj4eOjg4MDQ2xYcMGiXod\nHR34+9//DisrK+jq6mLy5MlIT08H0PPpwwHgm2++wR/+8AfweDwYGBjA0dER9fX1L2wDUOy04MJx\nDNnZ2f3qHAkh/ZCqu4f1FXm6MEZFRTEOh8M++eQT9uTJE9bc3Mz27dvHALAff/xRVO9vf/sb09HR\nYSdOnGBPnjxhkZGRTENDg+Xn54uOA4BdvHiR1dXVscrKSubi4sL09PRYa2srY4yxxsZGZmBgwOLj\n4xmfz2fl5eVsyZIlrKqqqkdtnDlzhunr67Po6OgXnpetrS0zNDTscnt9fT0DwEaPHt2vzrGnBlsX\nS0WgLvCKM9h+/wbNb42sfyTNzc2Mx+Ox1157Taz86NGjYkmEz+czHo/HAgICxPbV0dFhISEhjLH/\nfsHy+XxRHWEyKi4uZowx9tNPPzEA7MyZMxKx9KQNWbwoiTDGGIfDYUZGRgPyHAfbH7EiUBJRnMH2\n+0cv1rtQXFyM5uZmuLm5dVvv7t27aG5uxqRJk0Rlurq6GDFiRLdTfneePtzGxgZmZmYIDAxEWFgY\ngoKCRDORytuGvJqamsAYE61ENxDP8dq1a/D395d5v8FKOMUHXbPeu3btmtRFrtQVvRPpgvCPytTU\ntNt6TU1NAICNGzeKjb349ddfxdZ3fhFdXV1cunQJzs7OiImJgY2NDQICAsDn8xXWRk/98ssvAIAJ\nEyYAUM9zJIQoBt2JdIHL5QIAnj592m09YZLZvXs31q5d26s2HRwccPr0aVRVVSEhIQFxcXFwcHAQ\njexVRBs9cf78eQDAwoULAQzMc5w5cyaOHz/e6+MMFseOHcOyZcvominAYLubozuRLkyaNAkaGhr4\n5ptvuq03evRocLncXo9gLysrw507dwA8+9LesWMHXn75Zdy5c0dhbfREeXk5du/ejVGjRuHNN98E\noH7nSAhRHEoiXTA1NYWvry9OnDiBlJQU1NfX49atWzh48KBYPS6XizfeeANHjx5FcnIy6uvr0dHR\ngUePHkmsXdCdsrIyrF69+v/bu/eQpt4/DuDv5Vpz2mVWE9NWpiZd7EIWecsuZJGklmUGQf1hmEVb\nERRqVi41jRARjAjMoDLrV2GLLn8EjYrKDLsOuihZpuQ0U7da6tzz+0Nc3+V1c5dynxf4z9lzzudz\n5tzH85zzPA/evn2L9vZ2PH/+HJ8+fcLixYsHFcPUacEZY9BoNNDr9WCMoaGhAZcuXUJISAicnJxQ\nWlpquCfyt5wjIeQvZOcb+zZjztMnarWaJSQksPHjxzNXV1cWGhrKDh06xAAwLy8v9vLlS8YYY21t\nbezAgQNMLBYzLpfLJk6cyGJjY5lSqWQFBQVMIBAwAMzPz49VVVWx06dPszFjxjAAbMqUKez9+/es\nurqaBQcHM6FQyJycnNikSZNYamoq0+l0A8ZgjLFbt26x0aNHs4yMjD7PRy6Xszlz5jCBQMB4PB4b\nMWIEA2B4EmvRokVMJpOxb9++9dj3bzjHwXK0p2MsgZ7OshxH+/xxGBvkhPz/uO4+Xwc5XYfW3SdN\n/fuDR38fluNonz/qziKEEGI2KiKEEKu4e/cukpOTodfrsW7dOojFYvD5fHh6eiI6OhqvXr0y+ZgZ\nGRk9ljLgcDhG44sAYOnSpb2243A4cHV1BQDI5XLk5OQM+3VfrI2KCCHE4g4fPoz8/HykpKRAr9fj\nwYMHKC4uRlNTEx4+fAitVoslS5agrq7O5rmFhoYCAKKiosDn87FixQo0NzfbPI/hgooIIVag1WoR\nHBz8z8cwR3Z2NkpKSnD58mWMHj0aQNd68aGhoRAIBPD29kZmZiZaWlpw9uxZk49/7tw5sK4pmww/\nb968MWrD5/PR2trao11iYiL2799vaCeVSjF37lysWbMGOp1uSOftqKiIEGIFhYWFUKlU/3wMU1VW\nViItLQ3p6emGAbtcLhc3btwwajdt2jQAQFVVlVXyuHPnjqGAdaupqcGbN2+wfPlyo+1HjhzBixcv\nkJeXZ5VchjsqIoSga9xMbm4uZsyYgVGjRkEoFCImJsZo3i6JRAIej2e0Kt+uXbvg4uICDoeDxsZG\nAMCePXuwb98+VFVVgcPhwNfXF/n5+eDz+RCJRNixYwc8PDzA5/MRHByMsrIyi8QALLskgDny8/PB\nGENUVFS/7bRaLQAYxiLZQnZ2NqRSaY/tQqEQ4eHhyMvLo6fTzEBFhBB0/TeanJyM1NRUqFQq3L9/\nHzU1NQgLC0N9fT2Ari/IuLg4o/0KCgqQnp5utC0vLw9r166Fj48PGGOorKyERCLBtm3b8PPnT0il\nUlRXV6OiogI6nQ4rV65ETU3NkGMAMNwk1uv1lntzTHDz5k34+/sPuH7606dPAfy+P2GK5ORkCIVC\n8Hg8eHt7IyYmBuXl5f3uU1tbC4VCgdjY2F5fnz9/Pmpra/Hy5UuT83F0VESIw9NqtcjNzcX69eux\nZcsWjB07FgEBATh16hQaGxt7zFIwFFwu13C1M3PmTJw8eRJqtRpFRUUWOX5kZCRaW1uRlpZmkeOZ\n4sePH/j48SN8fHz6bFNfX4+SkhJIpVIEBQUNeMXyp61bt0Iul6OmpgYajQYXL17E58+fER4eDqVS\n2ed+2dnZ2L17N0aM6P0rz8/PDwDw+vVrk/IhVEQIgVKphEajQWBgoNH2hQsXgsfjGXU3WVpgYCAE\nAoFVpvS3NZVKBcZYv1chQUFBkEqliImJwe3btzFy5EiTYkyePBnz58+Hq6sreDweFi9ejKKiImi1\nWhQUFPS6T11dHeRyuWHFzt5059x91UkGj2bxJQ6v+/HO7vED/zVu3Dio1Wqrxh81ahQaGhqsGsMW\nfv36BaDrfPoiEolQWFiIWbNmWSxuQEAAnJycDEsY/CknJwfbt2833OjvjbOzM4Df50AGj4oIcXjj\nxo0DgF6LRXNzM7y8vKwWu6Ojw+oxbKX7i7i/wXsTJ040vN+Wotfrodfrey1eX79+RXFxMd69e9fv\nMdrb2wH8PgcyeNSdRRze7Nmz4erqimfPnhltLysrQ3t7OxYsWGDYxuVyDSs1WoJCoQBjzGglPEvH\nsBWRSAQOh4OWlpY+29y4cQOenp5mx1i1alWPbeXl5WCMISgoqMdrOTk52LJlC9zc3Po9bnfO7u7u\nZufmqKiIEIfH5/Oxb98+XLt2DefPn0draytev36NpKQkeHh4IDEx0dDW19cXTU1NKC0tRUdHBxoa\nGvDp06cex3Rzc0NdXR2qq6uhVqsNRUGv1+P79+/Q6XR49eoV9uzZA7FYbNRfP5QYpi4JYEkCgQDT\npk0zrAr6p8rKSri7u2PTpk09XouPj4e7uzsqKir6jVFbW4uSkhI0Nzejo6MDjx8/RkJCAsRiMZKS\nkoza1tfX48yZM9i7d++AuXfnHBAQMGBbYoyKCCHomqYjKysLMpkMEyZMQHh4OKZOnQqFQgEXFxdD\nu507d2LZsmXYvHkz/P39cfToUUMXSFBQkOFR3aSkJIhEIsycORNr1qxBU1MTgK4+94CAADg7OyMs\nLAzTp0/HvXv3jLpihhrDniIjI6FUKg3jQP6rvzEY7e3tUKlUuH79er/HX716NQ4ePAgvLy8IBALE\nxcUhJCQET548wfjx443aHj9+HFFRURCLxQPmXV5eDk9PT8yZM2fAtuQPNp143o5ovQTH8beu55CY\nmMjc3NzsnUavLPX38eHDB8blctm5c+dM2q+zs5OFhYWxwsLCIedgqsbGRsbn89mJEycscry/9fNn\nLXQlQogNDfcZY319fSGTySCTyaDRaAa1T2dnJ0pLS6FWqxEfH2/lDHs6cuQI5s2bB4lEYvPYwwEV\nEUKIRSUnJ2Pjxo2Ij4/v9yZ7N4VCgatXr+L27dsDjnS3tNzcXLx48QK3bt0yecwK6UJFhBAbSElJ\nQVFREVpaWuDt7Y0rV67YOyWryszMhEQiwbFjxwZsu2LFCly4cMFovjBbuH79Otra2qBQKCAUCm0a\nezihcSKE2EBWVhaysrLsnYZNRUREICIiwt5p9Ck6OhrR0dH2TuOfR1cihBBCzEZFhBBCiNmoiBBC\nCDEbFRFCCCFmoyJCCCHEbA73dBaHw7F3CsRG6HdtOnrPLGPDhg32TsFmOIw5xqLCX758waNHj+yd\nBiHEAUyePLnXWYWHI4cpIoQQQiyP7okQQggxGxURQgghZqMiQgghxGxcAP+zdxKEEEL+Tf8H9qHK\nJKv5WkwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVmgE2nijpXc",
        "colab_type": "text"
      },
      "source": [
        "# Resume training from existing weights ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQgyqPmoi_47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelFile = os.path.join(MODEL_DIR, \"lstm_text_gen-loss_1.2006.h5\") # None\n",
        "\n",
        "if modelFile is not None and os.path.exists(modelFile):\n",
        "  print(\"Initializing with weights from \", modelFile)\n",
        "  model.load_weights(modelFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTjuOEXzi1ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "ckpt_filepath=os.path.join(MODEL_DIR, \"lstm_text_gen-loss_{loss:.4f}.h5\")\n",
        "checkpoint_callback = ModelCheckpoint(ckpt_filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2zfOK40jusN",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dqk9QXrgKCf",
        "colab_type": "code",
        "outputId": "390c11a3-e08d-4c05-d017-d1670570e333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "callbacks = [print_callback]\n",
        "if modelDirExists:\n",
        "  callbacks.append(checkpoint_callback)\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=60,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "1559/1565 [============================>.] - ETA: 0s - loss: 2.5163\n",
            "----- Generating text after Epoch: 0\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"aps favour the growth of another and str\"\n",
            "\t\n",
            "aps favour the growth of another and strenge the the the the the the the the the the hat in the the the the presting the the the the prenge the the prespinge the the the the the the and and and the prenate the the the and the the the serenting of the the the the the the the the the the the mand and the the the the the the the in the the the the the the the ingerent on the serend the the the herere the here the preante the and and the se\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"aps favour the growth of another and str\"\n",
            "\t\n",
            "aps favour the growth of another and stre buthing the wire fired the berevey of the mingtous able frealid of ef and the hate the perenens to the a the with the sereres fat the there the the\n",
            "herere t eunt erelly the and the hathe in the wing hume thet of the the the the stered in the the with te the matle the heren) in the wally dulle inlt anle the is peresticouse the the the the that the ther of there the then caringith the precenting t\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.51525, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_2.5153.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 2.5153\n",
            "Epoch 2/60\n",
            "1558/1565 [============================>.] - ETA: 0s - loss: 2.1321\n",
            "----- Generating text after Epoch: 1\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"s one has\n",
            "a personal interest in denounc\"\n",
            "\t\n",
            "s one has\n",
            "a personal interest in denouncertang and the fore of the whild as and the worle and is the tould and inderingerestion of the sulise and inselforestion and intereation of the will of the manderation of the sound and in the preastion the more and instingeration and and inselfered and the istingerand and and and inderingerand and the with the wore and itselfered and and in the wath of the experestion and inderingestion and the re\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"s one has\n",
            "a personal interest in denounc\"\n",
            "\t\n",
            "s one has\n",
            "a personal interest in denouncesting whill gricesowion of a the giones of the hiscerecting conserimation and mand as the conseranion, in the semingerstomenand as onesting the periste erceastion for nothercestand on the isterention and a sally the withersed\n",
            "at anderian in the sulial of vereraned it be whe he was enfuredenterstang the buther, a dereation as inselficion of the meoderaint and the gerestand and orenores, in the pre\n",
            "\n",
            "Epoch 00002: loss improved from 2.51525 to 2.13181, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_2.1318.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 2.1318\n",
            "Epoch 3/60\n",
            "1557/1565 [============================>.] - ETA: 0s - loss: 1.9694\n",
            "----- Generating text after Epoch: 2\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"erb says,\n",
            "one remains a philosopher only\"\n",
            "\t\n",
            "erb says,\n",
            "one remains a philosopher only the persophess of the prost of the really the suphing the more the preated the sort the prost of the recores and the with the prost the with the sulf and the sull of the constion the prost of the reare the sume of the surt and the prost of the prost in the reare the every in the rectrent to the realing the prost of the prost of the conting the sulf the prost of the contertion and consting the pro\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"erb says,\n",
            "one remains a philosopher only\"\n",
            "\t\n",
            "erb says,\n",
            "one remains a philosopher only prost of the sighes and what been all that rearity. the wos grow and home has a tore the regel and man for has it belo not who lisk for all to the ray ligatiun of the revirity his bether and moter and the philosophicion and who has the consily to but which be of the corse men of to the rering of the preition of chissous of the will and conting and and porsent of the consing the prears of the rist\n",
            "\n",
            "Epoch 00003: loss improved from 2.13181 to 1.96917, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.9692.h5\n",
            "1565/1565 [==============================] - 29s 18ms/step - loss: 1.9692\n",
            "Epoch 4/60\n",
            "1564/1565 [============================>.] - ETA: 0s - loss: 1.8604\n",
            "----- Generating text after Epoch: 3\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \" spiritual fate, the unteachable in us, \"\n",
            "\t\n",
            " spiritual fate, the unteachable in us, the enting that the will and and the such a sting the consention of the strention and consention the sting the consention of the pistoun and and the sting the suppriest the conseration of the sting of the will the sting the the strention of the will the sting to the consent of the more the encoure the conceraling and the some to the consertion of the porsing and the sting the consention the every \n",
            "\n",
            "----- Generating with seed (diversity=0.50): \" spiritual fate, the unteachable in us, \"\n",
            "\t\n",
            " spiritual fate, the unteachable in us, and the pancion, the all the cants and and and which and a still to every, and the forle surfiling that and sumpented in the extonction and with an a ponderthing in the expention of the sthere the more not being the concence in the porse and man in the promon and and restire and belignt the love, and the pothing that the his not the herdermances,\n",
            "and is and in the suof a\n",
            "then the peristing over or\n",
            "\n",
            "Epoch 00004: loss improved from 1.96917 to 1.86044, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.8604.h5\n",
            "1565/1565 [==============================] - 30s 19ms/step - loss: 1.8604\n",
            "Epoch 5/60\n",
            "1560/1565 [============================>.] - ETA: 0s - loss: 1.7778\n",
            "----- Generating text after Epoch: 4\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"elieve it\n",
            "of me: i have always thought v\"\n",
            "\t\n",
            "elieve it\n",
            "of me: i have always thought very and the prose of the postion of the self and the strented to the can of the proses of constions and the partion of the moral the some a strented in the person of the prosent the person the postion, the prosent the present the more and still the for the prosting the sting of the prosent the person of the precises and and constions to the world the word and the sense of the prosent the person th\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"elieve it\n",
            "of me: i have always thought v\"\n",
            "\t\n",
            "elieve it\n",
            "of me: i have always thought very be one the restomed to be pownose be a sure of riffle to and his fell with the intrations, and to a strentes of that he free prensical it us of constioned the stance of indichisting interting the reanders of the consting as a to be it wo ho ho are man it and in the person of the remery lofe one hample in the constions of a stime to the self man of the\n",
            "cancertion, the such pronsting from the po\n",
            "\n",
            "Epoch 00005: loss improved from 1.86044 to 1.77751, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.7775.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.7775\n",
            "Epoch 6/60\n",
            "1559/1565 [============================>.] - ETA: 0s - loss: 1.7119\n",
            "----- Generating text after Epoch: 5\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"ce of the christian movement. that its t\"\n",
            "\t\n",
            "ce of the christian movement. that its the such a scoul for the such a such a some and its all the such a strong the such a strong and such as the streatises and a whole a religion of the suppicial of the strenges of the constion of the such as the subtion of the such a strong of the consention of the such a strong the consention of the sain as the such a strong to the conserations of the will to as the such a strong and a something and\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"ce of the christian movement. that its t\"\n",
            "\t\n",
            "ce of the christian movement. that its the some approves that is as a philosopher of the unoures and the fach a simple, and regard to a properation of the greacts spiritusions of the constious sumpinity of the lave there is not in deen to be the ortirnuned, and have one the science man may fain the wire to be a scoully in restimation and his saifience which has exped the regliom not of\n",
            "man in which the would and it was lide a fine the f\n",
            "\n",
            "Epoch 00006: loss improved from 1.77751 to 1.71215, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.7122.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.7122\n",
            "Epoch 7/60\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 1.6596\n",
            "----- Generating text after Epoch: 6\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \" the law of the weaker.=--whenever any p\"\n",
            "\t\n",
            " the law of the weaker.=--whenever any propery the some morality of the self-consitions and all the strenges and subjection of the strenges of the stronger of the self-cancess of the self-consitions and self--in the strenger of the strenger of the supersion of the self-consitions and and and and something the self-consition of the most and all the strangions and in the self-mantion of the stronger of the despression of the strenge of th\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \" the law of the weaker.=--whenever any p\"\n",
            "\t\n",
            " the law of the weaker.=--whenever any presers of the can it be no\n",
            "dow free the discine, on inferent and one in the prosentical process. the suppossion of the strung can in for his of indersthing the sturity and were of the deligional with the same and conscience of the strengly of the standing to the appositting and sincifulten man and also in the pissont of of will and present the comprect of the world to the same the world\"--what is \n",
            "\n",
            "Epoch 00007: loss improved from 1.71215 to 1.65956, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.6596.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.6596\n",
            "Epoch 8/60\n",
            "1560/1565 [============================>.] - ETA: 0s - loss: 1.6155\n",
            "----- Generating text after Epoch: 7\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"ithout in the least vitiating,\n",
            "with its \"\n",
            "\t\n",
            "ithout in the least vitiating,\n",
            "with its and the strange of the prosing and interpretion of the cance of the constion of the prosent of the proponsition of the self-concernes of the prosing of the self-ensirity of the moral of the consident of the constince of the same and consequently and the conscience of the sould of the pristration of the great spirit of the same a strong to the propersion of the constince of the constion of the pros\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"ithout in the least vitiating,\n",
            "with its \"\n",
            "\t\n",
            "ithout in the least vitiating,\n",
            "with its such a string dispossition of the prosing of the sersor of religious. the delight of the presention and constion as the can of the gistrous intertance of the desirtul which the canstion the ressince of the good of the privility of the doust the constince, the existeacting in the questions of experience to the to do more soult that the constinity of a new\"dectian of does to so good that the word ha\n",
            "\n",
            "Epoch 00008: loss improved from 1.65956 to 1.61534, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.6153.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.6153\n",
            "Epoch 9/60\n",
            "1563/1565 [============================>.] - ETA: 0s - loss: 1.5775\n",
            "----- Generating text after Epoch: 8\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"ensations had been\n",
            "gone through a hundre\"\n",
            "\t\n",
            "ensations had been\n",
            "gone through a hundreding and the same as a fould the self-distrusion of the instinction of the self one the one in the sense of the such a such a such a such a stand of the consention of the self-consestion of the self-conditions is the self-constion of the self-consition of the self-constion of the sense of the conscience of the same a consention of the self and the some and individual of the such propored that the \n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"ensations had been\n",
            "gone through a hundre\"\n",
            "\t\n",
            "ensations had been\n",
            "gone through a hundredain of genarion, and all the standing of the still. which man by the\n",
            "strangion of virwout of\n",
            "the encepting in the world in the consequences as latter is the can parting and the sense of the extentes to the contraintic like and the same the restous of madier that is order the such an any a delecaper of the religions and of the self-contrinary of sentiminal has its\n",
            "prociser the standing of the afte\n",
            "\n",
            "Epoch 00009: loss improved from 1.61534 to 1.57750, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.5775.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.5775\n",
            "Epoch 10/60\n",
            "1559/1565 [============================>.] - ETA: 0s - loss: 1.5456\n",
            "----- Generating text after Epoch: 9\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"thing that\n",
            "is in the end solemnly christ\"\n",
            "\t\n",
            "thing that\n",
            "is in the end solemnly christian the present of the conscience of the consideration of the problem of the consting in the consideration of the constraint in the master of the free of the strange of the conscience of the same a stronge of man as a such a strong in the strange of the contrary the constinct of a man and stand of the constitution of the contrary of the constinction of the master of the present and conception of t\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"thing that\n",
            "is in the end solemnly christ\"\n",
            "\t\n",
            "thing that\n",
            "is in the end solemnly christian of a man confulation to can a grate and its love in his to the old and that in this pronection of a can no looks it by a promong the art and a present of the regard to the religion of the lighter in the subtrest of anteration. the creation of the prichteres and experience of which and we are simply the case of and consention when even the higher one an every and pleasure of the will as a finde\n",
            "\n",
            "Epoch 00010: loss improved from 1.57750 to 1.54509, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.5451.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.5451\n",
            "Epoch 11/60\n",
            "1556/1565 [============================>.] - ETA: 0s - loss: 1.5164\n",
            "----- Generating text after Epoch: 10\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"here is an oriental exaltation of the\n",
            "mi\"\n",
            "\t\n",
            "here is an oriental exaltation of the\n",
            "mistrous of the strange of the self-constitual to the self--the same as the self--the strange of the self--the strange of the self--the superfuling of the stull with the stands of the subelity of the strange of the subjection of the strange of the strange of a still in the self-conscience of the self--the promprate of the self--the standing of the self-cances of the self-distrestion of the self-cons\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"here is an oriental exaltation of the\n",
            "mi\"\n",
            "\t\n",
            "here is an oriental exaltation of the\n",
            "mirdulfornssical instinct of all the \"deep of of the same means to the hasting of the belief in the species of to the seem that it is to seem to the more and and self-consequention, the most is the some a sure--in a light wither the stunding self-cance to german the standards the belief the strangific of the strangs of truth in the strange of a standing and of the pleasure of itself still to my pain\n",
            "\n",
            "Epoch 00011: loss improved from 1.54509 to 1.51687, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.5169.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.5169\n",
            "Epoch 12/60\n",
            "1563/1565 [============================>.] - ETA: 0s - loss: 1.4918\n",
            "----- Generating text after Epoch: 11\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"hest and greatest and\n",
            "richest, and putti\"\n",
            "\t\n",
            "hest and greatest and\n",
            "richest, and putting is a some discented in the most of the conscience of the self-can for the considerations and desires the world in the light the one is not all the same as the one who have been for the consideration of the world and desires of the world, and also the consitional and morality of the world of the most of the consideration of the world of the constitutions of the consequences and the same as the s\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"hest and greatest and\n",
            "richest, and putti\"\n",
            "\t\n",
            "hest and greatest and\n",
            "richest, and putting stard dis for the consequences and desprated, and the higher of the present and antiging one and stape af a bears for the most strange of man be over the supertion\" and it as a such distraited in must also and been displession that the interponations, and we live which has it is a philosophy be of which the freek the world be on acts the other souls.\n",
            "\n",
            "\n",
            "wais not into that the fundamental\n",
            "yeads o\n",
            "\n",
            "Epoch 00012: loss improved from 1.51687 to 1.49186, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.4919.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.4919\n",
            "Epoch 13/60\n",
            "1563/1565 [============================>.] - ETA: 0s - loss: 1.4687\n",
            "----- Generating text after Epoch: 12\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"s to do\n",
            "with much that is secret, new, s\"\n",
            "\t\n",
            "s to do\n",
            "with much that is secret, new, such a such a such a strong himself and the seems to the present and all the little of the self-constitution of the self-constitutist is the fact that the moral of the present in the moral of the present and consideration of the present of the self-constitution of the present in the prospression of a the same the herding the world and the world of the self-contraint in the present of the present of\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"s to do\n",
            "with much that is secret, new, s\"\n",
            "\t\n",
            "s to do\n",
            "with much that is secret, new, so that it weared individual to all the\n",
            "sperious will depressiance the whole always spirit with the one has lite a problem that it is all the history of its consideration of its and developter and all the world and the inither is allost and is also and in comparion of the considitions of the herver of the presenting and prodentive of the fundamental intropaning man who how seems\n",
            "to the world, that \n",
            "\n",
            "Epoch 00013: loss improved from 1.49186 to 1.46856, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.4686.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.4686\n",
            "Epoch 14/60\n",
            "1557/1565 [============================>.] - ETA: 0s - loss: 1.4477\n",
            "----- Generating text after Epoch: 13\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"ng of man into a pigmy with equal rights\"\n",
            "\t\n",
            "ng of man into a pigmy with equal rights of the same as the same to all the same are the self-conception of the souls of the stronges of the strong in the souls of the present of the superioration of the subjection of the stronger of the stronges of the stronges of the stronges of the stronges of the same at and the stronges of the stronger of the same to present in the self-cannot is the same and the standing of the present of the same\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"ng of man into a pigmy with equal rights\"\n",
            "\t\n",
            "ng of man into a pigmy with equal rights in the mark of the some of the truth as the respect of its preasure, and what is the most degres, in the \"with more to as understond of a man of the mankind. it is something lise of the light of the subject and strange of the prante, which we free the presite of the standary and way the scholong the standaring of the same \"interption.\" it is the strong of the presentice, of the common and every p\n",
            "\n",
            "Epoch 00014: loss improved from 1.46856 to 1.44818, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.4482.h5\n",
            "1565/1565 [==============================] - 30s 19ms/step - loss: 1.4482\n",
            "Epoch 15/60\n",
            "1564/1565 [============================>.] - ETA: 0s - loss: 1.4284\n",
            "----- Generating text after Epoch: 14\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"us consequences, fruitful and fearful at\"\n",
            "\t\n",
            "us consequences, fruitful and fearful attempt of the subjection of the self-constratity of the self-constitution of the same the person of the self-constraint in the self-constraint of the self-constraint of the self-constration of the same to be a man have always something in the self-constraint of the self-constraint of the same the most of the self-conception of the presenting of the same man who have all the same the world of the se\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"us consequences, fruitful and fearful at\"\n",
            "\t\n",
            "us consequences, fruitful and fearful attempts of the exceptionion of the same to greating of the person of the soul to such an also be and internors, the respent to the person of the precisest of the strength of the hown-what has been dowing, and so masters and subsent, the constraint evil wherefore the certain comprehention of the soul of all the soul have proved now the seen un the precisely of the case hitherto has its any resendent\n",
            "\n",
            "Epoch 00015: loss improved from 1.44818 to 1.42822, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.4282.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.4282\n",
            "Epoch 16/60\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 1.4107\n",
            "----- Generating text after Epoch: 15\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"hat there is\n",
            "a hatred of the virgin fore\"\n",
            "\t\n",
            "hat there is\n",
            "a hatred of the virgin fore of the self-constraint of the self-conception of the soul of the self-contrality of the self-contrality of the sense of all the strength of the same to all the standards of the subjection of the self-distrest of the soul of the secret in the same mistrality of the self-contemption of the strength of the present of the self-contrality of the society the strength, in the sense of all the stronges o\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"hat there is\n",
            "a hatred of the virgin fore\"\n",
            "\t\n",
            "hat there is\n",
            "a hatred of the virgin fore is the so that and the scholer of all the free spirit of all the individuals of the sigress of man indeed, the extention of the subject of all the world of the same deceives which the contrary, that the world in order and morality, that it so dangerous as a master of the self-such and the feeling of the other with the strength of may lite read and contral considerations of the serious of which th\n",
            "\n",
            "Epoch 00016: loss improved from 1.42822 to 1.41073, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.4107.h5\n",
            "1565/1565 [==============================] - 30s 19ms/step - loss: 1.4107\n",
            "Epoch 17/60\n",
            "1564/1565 [============================>.] - ETA: 0s - loss: 1.3947\n",
            "----- Generating text after Epoch: 16\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \",\n",
            "punishments and every kind of indicati\"\n",
            "\t\n",
            ",\n",
            "punishments and every kind of indication and all the same privisent of the proporation of the problem of the spirit and the present in the moral of the procession of the soul of the spirit of all the spirit of the same moral of the such a man have the spentitions of the spirit of the proporation of the subjection of the world of the spett of all the such a their philosophers that it is the spetting the religious and the spirit of the \n",
            "\n",
            "----- Generating with seed (diversity=0.50): \",\n",
            "punishments and every kind of indicati\"\n",
            "\t\n",
            ",\n",
            "punishments and every kind of indication and\n",
            "enterthing of the bast such a play the same posisitism of the self-conscience, has a religious distance the discovered in the probarus of the soul of all the morily sensition, than the same the whole in the speicious prichism that is becomes to extent the spirit and before the persons of the entight of distrustly and the self-concemsion of the same regard to the power of \"proporditious\" of \n",
            "\n",
            "Epoch 00017: loss improved from 1.41073 to 1.39485, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.3949.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.3949\n",
            "Epoch 18/60\n",
            "1559/1565 [============================>.] - ETA: 0s - loss: 1.3803\n",
            "----- Generating text after Epoch: 17\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"is\n",
            "world and the next world, where in th\"\n",
            "\t\n",
            "is\n",
            "world and the next world, where in the same men of the strength of the process of the present of the procession of the self-constitution of the self-constitutism of the present state of the world of the strength of the propers of the present of the process of the self-constitution of the more of the propers and present the the stronges of a man as a religious experience of the self-constration of the individual the moral of the prese\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"is\n",
            "world and the next world, where in th\"\n",
            "\t\n",
            "is\n",
            "world and the next world, where in the stand its own what is the higher of the moralists and approped to be the world and its exceptional easis, and historther even the nerm still would be far as a philosopher, and like the belief on the man who has it is not concert in the considerion of the serve of the assurious and its evily the persons of the light the great spiritual conscience of the powerful of all these can german the much o\n",
            "\n",
            "Epoch 00018: loss improved from 1.39485 to 1.38015, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.3801.h5\n",
            "1565/1565 [==============================] - 30s 19ms/step - loss: 1.3801\n",
            "Epoch 19/60\n",
            "1559/1565 [============================>.] - ETA: 0s - loss: 1.3655\n",
            "----- Generating text after Epoch: 18\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \" only a\n",
            "nostrum,--that what is fair to o\"\n",
            "\t\n",
            " only a\n",
            "nostrum,--that what is fair to one may be a man has been sense of the self-conception of the same man as the propers in the sense of the self-constitution of the strength, which is the literaring the problem of the self-constitutism of the problem of the conscience, the constitution of the subjection of the sublimation of the same time the constraint in the problem of the constitution of the problem of the propers in the problem\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \" only a\n",
            "nostrum,--that what is fair to o\"\n",
            "\t\n",
            " only a\n",
            "nostrum,--that what is fair to order to the taste is nature for all whose can be more such as so that it is only their problem of the\n",
            "soul has not to power for the expression and have only the truth, is always and appreciate the propers to the extent of him of the consequent of something the pliom of the prestrion in the self-decesting, as the laught the word hands which is a master of his sense and possible of an experition of \n",
            "\n",
            "Epoch 00019: loss improved from 1.38015 to 1.36585, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.3659.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.3659\n",
            "Epoch 20/60\n",
            "1564/1565 [============================>.] - ETA: 0s - loss: 1.3522\n",
            "----- Generating text after Epoch: 19\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"t this already happened? have\n",
            "not we our\"\n",
            "\t\n",
            "t this already happened? have\n",
            "not we our for the standing of the same trangs of the same pression of the self-deet of the present in the most spirit of the stronger of the serve sensitive and self-decesting the self-deverence of the self-decesting the prosent of the self-decesting of a stronger of the present in the world of all the self-decesting of the soul of the self-decelting of the same pression of the self-plaining of the self-de\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"t this already happened? have\n",
            "not we our\"\n",
            "\t\n",
            "t this already happened? have\n",
            "not we our shame of such a god in commaning a such a fact to the case with the sublimen in the probituaning of all and also mask of a very common in the soul of a light the pride and interpretence of plance, which is not to general conceptions of the most standing of a fact that the most saymen. it is to say a thing he resple a rifrish only the world of religion of the world and the most depect and say alwa\n",
            "\n",
            "Epoch 00020: loss improved from 1.36585 to 1.35225, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.3522.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.3522\n",
            "Epoch 21/60\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 1.3404\n",
            "----- Generating text after Epoch: 20\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"y\n",
            "incalculable quantity of intellectual \"\n",
            "\t\n",
            "y\n",
            "incalculable quantity of intellectual to the self-deception of the subjection of the conscience and conscience in the self-constitution of the subjection of the subtlety of the standard of the subtle, that is always being the standing man is the standard of the subjection of the consideration of the conscience which is allow the delight in the sense of the delight the contradical conscience of the problem of the conscience in the stan\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"y\n",
            "incalculable quantity of intellectual \"\n",
            "\t\n",
            "y\n",
            "incalculable quantity of intellectual to an inferced manifestous of virition of the world be the individualing concerning to the commanding experience and consideration of the sense of as the saint matter, simply that is the reading and extentive conficued so this and the powerful of all the spirit and extentary in the other soul strange in the self-dentinges of the self-contrums. and the contries\n",
            "in the bust of the some his own belon\n",
            "\n",
            "Epoch 00021: loss improved from 1.35225 to 1.34038, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.3404.h5\n",
            "1565/1565 [==============================] - 30s 19ms/step - loss: 1.3404\n",
            "Epoch 22/60\n",
            "1563/1565 [============================>.] - ETA: 0s - loss: 1.3278\n",
            "----- Generating text after Epoch: 21\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"r \"experience.\"--artists have here perha\"\n",
            "\t\n",
            "r \"experience.\"--artists have here perhaps her his cannot man, as a retarned the belief and the present is the world in the same things and the strength, the same man for general that it is the most delicate of the morality of the self-destrivional and the sense of the self-denting of the most deare the themselves and the same man there are not the most seemity in the self-denting of the presenting of the self-destricion of the self-den\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"r \"experience.\"--artists have here perha\"\n",
            "\t\n",
            "r \"experience.\"--artists have here perhaps the worth of every processian even upon the fact that it is the former power, and an ad\n",
            "in the soul, would be free spirit but for the them. this should be present is a man from a presertion of the present\n",
            "withing, and the most refined and distrest at the same not be supportinity, of the servent intention, and such as imperfected to soul, when the themselves and almost the\n",
            "moral is the too inder\n",
            "\n",
            "Epoch 00022: loss improved from 1.34038 to 1.32795, saving model to /content/gdrive/My Drive/Colab Notebooks/NYU/Models/lstm_text_gen-loss_1.3280.h5\n",
            "1565/1565 [==============================] - 29s 19ms/step - loss: 1.3280\n",
            "Epoch 23/60\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 1.3170\n",
            "----- Generating text after Epoch: 22\n",
            "\n",
            "----- Generating with seed (diversity=0.20): \"re is any pleasure in administering pain\"\n",
            "\t\n",
            "re is any pleasure in administering painful really souls in the more understood and the sense of the sense of the sense of the sense of the self-develops and more power of the strength of the same as the sense of the sense of the sense of the sense of the sense of the sense of the sense of the stand of the self-develops and prace of the strength in the sense of the self-development of the self-distrest and stronger of the sense of the s\n",
            "\n",
            "----- Generating with seed (diversity=0.50): \"re is any pleasure in administering pain\"\n",
            "\t\n",
            "re is any pleasure in administering painful becomes that and has its whee perhaps a plate there is the lass ma"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}