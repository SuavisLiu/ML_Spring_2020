{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{\\tp}{\\mathbf{{(t)}}}\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro `_latex_std_` created. To execute, type its name (without quotes).\n",
      "=== Macro contents: ===\n",
      "get_ipython().run_line_magic('run', 'Latex_macros.ipynb')\n",
      " "
     ]
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import neural_net_helper\n",
    "%aimport neural_net_helper\n",
    "\n",
    "nnh = neural_net_helper.NN_Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretting Representations: Preview\n",
    "\n",
    "We have described an $L$ layer (Sequential) Neural Network as\n",
    "- a sequence of tranformations of the input\n",
    "    - each transformation a *layer* $1 \\le \\ll \\le (L-1)$, producing a new *representation* $\\y_\\llp$\n",
    "- that feed the final representation $\\y_{(L-1)}$ to a *head* (classifier, regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center>Layers</center>\n",
    "    <br>\n",
    "<img src=images/NN_Layers.jpg>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Is it possible to *interpret* each representation $\\y_\\llp$ ?\n",
    "- What do the new \"synthetic features\" mean ?\n",
    "- Is there some structure among the new features ?\n",
    "    - e.g., does each feature encode a \"concept\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will briefly introduce the topic of Interpretation.\n",
    "\n",
    "A deeper dive will be the subject of a later lecture.\n",
    "\n",
    "Our goal, for the moment, is to motivate Autoencoders.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretation 1: Clustering of examples\n",
    "\n",
    "One way to try to interpet $\\y_\\llp$ is relative to a dataset $\\langle \\X, \\y \\rangle = \\{ \\x^\\ip, y^\\ip | 1 \\le i \\le m \\}$\n",
    "\n",
    "By passing each example $\\x^\\ip$ through the layers to obtain $\\y^\\ip_\\llp$ we create a mapping from examples to layer $\\ll$ representations\n",
    "$$\n",
    "\\langle \\X, \\y^\\ip_\\llp \\rangle = \\{ \\x^\\ip, y^\\ip_\\llp | 1 \\le i \\le m \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Mapping inputs to layer l representations</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Representation_1.jpg\" width=400></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's create a scatter plot of each example's representation $\\y^\\ip_\\llp$ \n",
    "- In $n_\\llp$-dimensional space\n",
    "- Labelling each point \n",
    "- With the target $\\y_\\llp$\n",
    "- Or with a set of input atttributes, e.g., $(\\x^\\ip_j, \\x^\\ip_{j'})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Perhaps clusters of examples will appear.\n",
    "\n",
    "If all points in the cluster have the same label\n",
    "- We might be able to identify the representation with a target or set of input features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is an example of the representation of the MNIST digits in an intermediate layer of a particular network\n",
    "- The output of the Encoder half of an Autoencoder\n",
    "- Which we will study in a subsequent lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center>MNIST clustering produced by a VAE</center>\n",
    "    <br>\n",
    "<img src=images/VAE_plot_test-in_latent.png width=800>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Each point is an example $\\x^\\ip$\n",
    "- With coordinates chosen from two of the synthetic features in $\\y_\\llp$\n",
    "- The color corresponds to the label $\\y^\\ip$ (i.e., the digit that is represented by the image)\n",
    "\n",
    "You can see that some digits form tight clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By understanding\n",
    "- The commonality of examples within a cluster\n",
    "- How the digit label's vary as a synthetic feature varies\n",
    "\n",
    "we might be able to infer meaning of the synthetic features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The first two synthetic features in $\\y_\\llp$ of MNIST may correspond to properties of those digits\n",
    "- digits with \"tops\"\n",
    "- digits with \"curves\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note**\n",
    "\n",
    "This is not too different from trying to interpret Principal Components:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretation 2: Examining the latent space\n",
    "\n",
    "Suppose we could *invert* the representation $\\y_\\llp$ to obtain a value $\\x$ that lies in the input domain.\n",
    "\n",
    "Then \n",
    "- By perturbing individual synthetic features $\\y_{\\llp,j}$ in a given representation $\\y_\\llp$ to obtain $\\y'_\\llp$\n",
    "- And examining the effect on the inverted value $\\x'$\n",
    "- We might be able to assign meaning to the layer $\\ll$ feature $y_{\\llp,j}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that the invered value $\\x'$ **is not necessarily** (and probably not) a value in training set $\\X$ !\n",
    "- It is merely a value obtained by the mathematical inversion of a function\n",
    "- Especially since the perturbed $\\y'$ may not be the mapping of any example $\\x^\\ip \\in \\X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Invert layer l representation</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Representation_2.jpg\" width=800></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here are the inverted images obtained by perturbing two synthetic features in $\\y_\\llp$\n",
    "- Horizontal axis perturbs one feature\n",
    "- Vertical axis perturbs a second feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center>MNIST clustering produced by a VAE</center>\n",
    "    <br>\n",
    "<img src=images/VAE_examine_latent.png width=1000>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some observations (with possible intepretation)\n",
    "- Does the  synthetic feature on the horizontal axis control slant ?\n",
    "    - Examine 0's along bottom row\n",
    "- Does the synthetic feature on the vertical axis control \"curviness\" ?\n",
    "    - Examine the 2's column at the right edge, from bottom to top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There is *no reason to expect* that the inversion of an arbitrary representation\n",
    "*looks like* a digit but it does !\n",
    "\n",
    "Perhaps\n",
    "- The mapping from inputs to representations is such that similar inputs have very similar representations\n",
    "- Or we impose some constraints on the inversion to force the inverted value to look like a digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order for this method to work, we must be able to *invert* $\\y_\\llp$.\n",
    "\n",
    "We will show how to do this in a later lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deja vu: have we seen this before ?\n",
    "\n",
    "These two methods of interpretation have been encountered in an earlier lecture\n",
    "- mapping original features $\\x^\\ip$ to synthetic features $\\tilde{\\x}^\\ip$\n",
    "- inverting synthetic feature $\\tilde{\\x}^\\ip$ to obtain original feature $\\x^\\ip$\n",
    "\n",
    "Principal Component Analysis (PCA) !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "PCA is an Unsupervised Learning task that can be used for\n",
    "- dimensionality reduction\n",
    "- clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The key to it's intepretability was the simplicity of transforming and inverting\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll]\\\\\n",
    "\\X & = & U \\Sigma V^T & \\text{SVD decomposition of } \\X\\\\\n",
    "\\tilde\\X & = & \\X V  & \\text{tranformation to synthetic features}\\\\\n",
    "\\X & = & \\tilde\\X V^T  & \\text{inverse tranformation to original features}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The transformation $V$ via matrix multiplication is *linear*.\n",
    "\n",
    "We will explore *non-linear, invertable* transformations during our study of Autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Neural Networks have the reputation of being magical but opaque.\n",
    "\n",
    "We hope this brief introduction to interpretation provides some hope that we can understand their inner workings.\n",
    "\n",
    "A separate lecture will explore this topic in greater depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
